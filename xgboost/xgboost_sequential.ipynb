{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jjLREnOAUH6r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numba import jit\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NWGpSJ29bVr4"
      },
      "outputs": [],
      "source": [
        "class Tree:\n",
        "    def __init__(self, max_depth = 3, min_samples = 1, min_child_weight = 1, min_impurity = 0, gamma = 0):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples = min_samples\n",
        "        self.min_child_weight = min_child_weight\n",
        "        self.min_impurity = min_impurity\n",
        "        self.gamma = gamma\n",
        "        self.tree = {}\n",
        "        self.fbs_time = 0\n",
        "\n",
        "    def split_data(self, X, feature_idx, split_value):\n",
        "        left_idx = X[:, feature_idx] <= split_value\n",
        "        right_idx = X[:, feature_idx] > split_value\n",
        "        return left_idx, right_idx\n",
        "\n",
        "    def similarity(self, residual, probs):\n",
        "        numerator = np.sum(residual) ** 2\n",
        "        denominator = np.sum(probs * (1 - probs)) + self.min_impurity\n",
        "        return numerator / denominator\n",
        "    \n",
        "    def cover(self, probs):\n",
        "        return np.sum(probs * (1 - probs))\n",
        "\n",
        "    def find_best_split(self, X, residual, probs):\n",
        "        best_gain = -np.inf\n",
        "        best_split_feature_idx = None\n",
        "        best_split_value = None\n",
        "\n",
        "        for feature_idx in range(X.shape[1]):\n",
        "            feature_values = X[:, feature_idx]\n",
        "            unique = np.unique(feature_values)\n",
        "            split_values = np.zeros(len(unique) - 1)\n",
        "\n",
        "            for i in range(len(split_values)):\n",
        "                split_values[i] = (unique[i] + unique[i + 1]) / 2\n",
        "\n",
        "            for value in split_values:\n",
        "                left_idx, right_idx = self.split_data(X, feature_idx, value)\n",
        "                p_left = probs[left_idx]\n",
        "                p_right = probs[right_idx]\n",
        "\n",
        "                if (len(left_idx) < self.min_samples or len(right_idx) < self.min_samples\n",
        "                    or self.cover(p_left) < self.min_child_weight or self.cover(p_right) < self.min_child_weight):\n",
        "                    continue\n",
        "\n",
        "                r_left = residual[left_idx]\n",
        "                r_right = residual[right_idx]\n",
        "                \n",
        "                gain = self.similarity(r_left, p_left) + self.similarity(r_right, p_right) - self.similarity(residual, probs) \n",
        "\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_split_feature_idx = feature_idx\n",
        "                    best_split_value = value\n",
        "\n",
        "        if(best_gain - self.gamma < 0):\n",
        "            best_split_feature_idx = None\n",
        "            best_split_value = None\n",
        "\n",
        "        return best_split_feature_idx, best_split_value\n",
        "\n",
        "\n",
        "    def compute_output(self, residual, probs):\n",
        "        numerator = np.sum(residual)\n",
        "        denominator = np.sum(probs * (1 - probs)) + self.min_impurity\n",
        "        return numerator / denominator\n",
        "    \n",
        "\n",
        "    def build_tree(self, X, residual, probs, depth):\n",
        "        if depth >= self.max_depth or len(X) <= self.min_samples:\n",
        "            return self.compute_output(residual, probs)\n",
        "\n",
        "        start = time.time()\n",
        "        split_feature_idx, split_value = self.find_best_split(X, residual, probs)\n",
        "        end = time.time()\n",
        "        self.fbs_time += (end - start)\n",
        "\n",
        "        if split_feature_idx is None:\n",
        "            return self.compute_output(residual, probs)\n",
        "\n",
        "        left_idx, right_idx = self.split_data(X, split_feature_idx, split_value)\n",
        "        left_child = self.build_tree(X[left_idx], residual[left_idx], probs[left_idx], depth + 1)\n",
        "        right_child = self.build_tree(X[right_idx], residual[right_idx], probs[right_idx], depth + 1)\n",
        "\n",
        "        self.tree = {\n",
        "            'split_feature_idx': split_feature_idx,\n",
        "            'split_value': split_value,\n",
        "            'left_child': left_child,\n",
        "            'right_child': right_child\n",
        "        }\n",
        "        return self.tree\n",
        "\n",
        "\n",
        "    def get_output(self, x, tree):\n",
        "        if isinstance(tree, dict):\n",
        "            split_feature_idx = tree['split_feature_idx']\n",
        "            split_value = tree['split_value']\n",
        "            if x[split_feature_idx] <= split_value:\n",
        "                return self.get_output(x, tree['left_child'])\n",
        "            else:\n",
        "                return self.get_output(x, tree['right_child'])\n",
        "        else:\n",
        "            return tree\n",
        "        \n",
        "        \n",
        "    def fit(self, X, residual, probs):\n",
        "        depth = 0\n",
        "        self.tree = self.build_tree(X, residual, probs, depth)\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self.get_output(x, self.tree) for x in X])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "b30KzBDXJuy2"
      },
      "outputs": [],
      "source": [
        "class XGBoost:\n",
        "    def __init__(self, n_estimators, learning_rate, min_impurity = 1e-7, gamma = 0, min_child_weight = 1, max_depth = 3):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.initial_prediction = 0.5\n",
        "        self.min_impurity = min_impurity\n",
        "        self.min_child_weight = min_child_weight\n",
        "        self.max_depth = max_depth\n",
        "        self.gamma = gamma\n",
        "        self.models = []\n",
        "        self.fbs_time = 0\n",
        "        self.logodds_time = 0\n",
        "        self.residual_time = 0\n",
        "        self.logodds_predict_time = 0\n",
        "        self.pred_time = 0\n",
        "\n",
        "    def compute_logodds(self, p):\n",
        "        return np.log(p / (1 - p)).astype(np.float64)\n",
        "\n",
        "    def residual(self, y_true, y_pred):\n",
        "        return (y_true - y_pred).astype(np.float64)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        data = X\n",
        "        predictions = np.full(len(y), self.initial_prediction, dtype = np.float64)\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            probs = np.copy(predictions)\n",
        "            start = time.time()\n",
        "            residual = self.residual(y, predictions)\n",
        "            end = time.time()\n",
        "            self.residual_time += (end - start)\n",
        "\n",
        "            model = Tree(min_impurity = self.min_impurity, gamma = self.gamma, max_depth = self.max_depth)\n",
        "            model.fit(data, residual, probs)\n",
        "            self.fbs_time += model.fbs_time\n",
        "\n",
        "            start = time.time()\n",
        "            log_odds = self.compute_logodds(predictions)\n",
        "            end = time.time()\n",
        "            self.logodds_time += (end - start)\n",
        "\n",
        "            start = time.time()\n",
        "            temp = log_odds + self.learning_rate * model.predict(data)\n",
        "            end = time.time()\n",
        "            self.logodds_predict_time += (end - start)\n",
        "\n",
        "            start = time.time()\n",
        "            predictions = np.around(np.exp(temp) / (1 + np.exp(temp)), decimals = 14)\n",
        "            end = time.time()\n",
        "            self.pred_time += (end - start)\n",
        "\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        predictions = np.full(len(X), self.initial_prediction)\n",
        "        for model in self.models:\n",
        "            temp = np.log(predictions / (1 - predictions)) + self.learning_rate * model.predict(X)\n",
        "            predictions = np.around(np.exp(temp) / (1 + np.exp(temp)), decimals = 14)\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = np.load('test_2label.npz', allow_pickle=True)\n",
        "X_train = data['X_train']\n",
        "y_train = data['y_train']\n",
        "X_test = data['X_test']\n",
        "y_test = data['y_test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thư viện có sẵn : 0.78\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "model = xgb.XGBClassifier(n_estimators = 100, learning_rate = 0.3, gamma = 0, max_depth = 3, min_child_weight = 1)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred2 = model.predict(X_test)\n",
        "print(\"Thư viện có sẵn : \" + str(accuracy_score(y_test, y_pred2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tự build : 0.7875\n"
          ]
        }
      ],
      "source": [
        "xgb_model = XGBoost(n_estimators = 100, learning_rate = 0.3, min_impurity = 0, gamma = 0)\n",
        "start = time.time()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "pred = xgb_model.predict_proba(X_test)\n",
        "y_pred1 = (pred > 0.5).astype(int)\n",
        "print(\"Tự build : \" + str(accuracy_score(y_test, y_pred1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training time: 113.34811019897461 seconds\n",
            "Find best split: 112.6448016166687 seconds\n",
            "Tính residual: 0.0018894672393798828 seconds\n"
          ]
        }
      ],
      "source": [
        "print(f'Total training time: {end - start} seconds')\n",
        "print(f'Find best split: {xgb_model.fbs_time} seconds')\n",
        "print(f'Tính residual: {xgb_model.residual_time} seconds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "''' Đọc data\n",
        "train = np.load('<tên file>.npz',allow_pickle=True)\n",
        "X_train = train['data']\n",
        "y_train = train['label']\n",
        "\n",
        "test = np.load('<tên file>.npz',allow_pickle=True)\n",
        "X_test = test['data']\n",
        "y_test = test['label']\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "''' Mã giả của MultiClassifier\n",
        "class Multi:\n",
        "    __init__():\n",
        "        self.models = []\n",
        "        self.time = 0\n",
        "\n",
        "    fit():\n",
        "        for y_i in labels:\n",
        "            y_2labels = (y == y_i).astype(int)\n",
        "            model = XGBoost(...)\n",
        "            model.fit(X, y_2labels)\n",
        "            self.models.append(model)\n",
        "            Tính thời gian + lưu thời gian\n",
        "\n",
        "    predict():\n",
        "        preds = []\n",
        "        for model in self.models:\n",
        "            preds.append(model.predict_proba(X_test))\n",
        "        y_pred = np.argmax(preds, axis = 0)\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    show_time():  -> để show ra hàm nào mất thời gian nhất & cần song song -> tùy ý \n",
        "        ....\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
