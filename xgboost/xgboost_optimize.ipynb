{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5-KyM3YaUOs"
      },
      "source": [
        "## Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Uf7CxvnGUzot"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "from numba import cuda\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N9O6QF9aUO2"
      },
      "source": [
        "## Cài đặt phiên bản XGBoost cải tiến"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-8MdE_AaUO3"
      },
      "source": [
        "Áp dụng một số cải tiến giúp cải thiện hiệu suất mô hình, giảm số lần truy cập bộ nhớ, giảm thời gian thực thi nhưng vẫn đảm bảo được độ chính xác của mô hình"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFEeUf09aUO4"
      },
      "source": [
        "#### Xét hàm **`compute_split_value()`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNojeG-ez5-b"
      },
      "source": [
        "Tạo hàm `compute_split_value_optimize()` áp dụng các kĩ thuật cải tiến lên hàm song song hóa ban đầu\n",
        "\n",
        "- Cải tiến 1:\n",
        "  \n",
        "- Cải tiến 2: Dữ liệu của sample X nằm ở bộ nhớ GMEM, và mỗi lần đọc dữ liệu của X thì các thread đều phải chạy xuống GMEM. Vì vậy sử dụng SMEM chứa phần dữ liệu mong muốn để tính split_value. Giả sử kích thước block là 4 x 4, thì kích thước share là 5 x 4 (vì 1 $split\\_value$ element cần 2 $x$ elements). Các thread sẽ lấy phần dữ liệu ứng với chỉ số `(row, col)` của chúng và ghi vào SMEM, đối với phần dữ liệu còn lại:\n",
        "  - Nếu toàn bộ block nằm trong phạm vi `split_array` thì dữ liệu còn lại sẽ do các thread có `ty = 0` xử lý\n",
        "  - Nếu chỉ có 1 phần block nằm trong phạm vi `split_array` thì dữ liệu còn lại sẽ do các thread có `ty` nằm ngay phạm vi ranh giới xử lý"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r3yTBRrzUzox"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def compute_split_value_optimize(input, output):\n",
        "    shared = cuda.shared.array((33, 32), dtype = np.float64)\n",
        "    r = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
        "    c = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "    tx, ty = cuda.threadIdx.x, cuda.threadIdx.y\n",
        "\n",
        "    if r < output.shape[0] and c < output.shape[1]:\n",
        "        shared[ty, tx] = input[r, c]\n",
        "\n",
        "        if ty == 0 and r + cuda.blockDim.y < output.shape[0]:\n",
        "            shared[ty + cuda.blockDim.y, tx] = input[r + cuda.blockDim.y, c]\n",
        "\n",
        "        if r + 1 >= output.shape[0]:\n",
        "            shared[ty + 1, tx] = input[r + 1, c]\n",
        "\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        if shared[ty, tx] != shared[ty + 1, tx]:\n",
        "            tmp = (shared[ty, tx] + shared[ty + 1, tx]) / 2\n",
        "            output[r, c] = tmp\n",
        "        else:\n",
        "            output[r, c] = np.nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLsVTr45aUO7"
      },
      "source": [
        "#### Xét hàm **`compute_gain()`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n1z6NWrVY7R"
      },
      "source": [
        "Tạo hàm `compute_split_value_optimize()` áp dụng các kĩ thuật cải tiến lên hàm song song hóa ban đầu\n",
        "\n",
        "- Cải tiến 1:\n",
        "  \n",
        "- Cải tiến 2: Dữ liệu của X, residual, prob và root gain đều nằm ở bộ nhớ GMEM, mỗi lần đọc dữ liệu thì các thread đều phải chạy xuống GMEM. Do vậy sử dụng SMEM load phần dữ liệu X, residual, prob, root gain mong muốn, phục vụ cho việc so sánh giá trị và tính gain. Với root gain, ta sẽ để thread có chỉ số `(tx = 0, ty = 0)` load dữ liệu vào SMEM. Với các dữ liệu còn lại, ta sẽ chia phần dữ liệu mà block cần thành nhiều phần nhỏ. Ở lần xử lý đầu tiên, block sẽ load một phần nhỏ của dữ liệu từ GMEM vào SMEM, rồi mỗi thread trong block đọc dữ liệu ở SMEM để tính một phần kết quả; ở lần xử lý kế, block sẽ load phần nhỏ tiếp theo (ghi đè lên dữ liệu cũ) và tính tiếp từ kết quả đang tính trước đó, tiếp tục cho đến hết."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ew5kLAPoP0Ma"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def compute_gain_optimize(split, output, X, residuals, p, lambda_, min_child_weight, min_samples, root_gain):\n",
        "    c, r = cuda.grid(2)\n",
        "    tx, ty = cuda.threadIdx.x, cuda.threadIdx.y\n",
        "    shared_X = cuda.shared.array((32, 32), dtype = np.float64)\n",
        "    shared_residual = cuda.shared.array((32), dtype = np.float64)\n",
        "    shared_prob = cuda.shared.array((32), dtype = np.float64)\n",
        "    shared_root_gain = cuda.shared.array((1), dtype = np.float64)\n",
        "    left_nu, right_nu, left_de, right_de, left_samples, right_samples = 0, 0, 0, 0, 0, 0\n",
        "\n",
        "    if r < split.shape[0] and c < split.shape[1]:\n",
        "        split_val = split[r, c]\n",
        "    else:\n",
        "        split_val = np.nan\n",
        "    if tx == 0 and ty == 0:\n",
        "        shared_root_gain[0] = root_gain\n",
        "\n",
        "    for phase in range(math.ceil(X.shape[0] / 32)):\n",
        "        if c < X.shape[1] and phase * 32 + ty < X.shape[0]:\n",
        "            shared_X[ty, tx] = X[phase * 32 + ty, c]\n",
        "            if tx == 0:\n",
        "                shared_residual[ty] = residuals[phase * 32 + ty]\n",
        "                shared_prob[ty] = p[phase * 32 + ty]\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        if split_val != np.nan:\n",
        "            for i in range(shared_X.shape[0]):\n",
        "                if phase * 32 + i < X.shape[0]:\n",
        "                    if shared_X[i, tx] <= split_val:\n",
        "                        left_nu += shared_residual[i]\n",
        "                        left_de += shared_prob[i] * (1 - shared_prob[i])\n",
        "                        left_samples += 1\n",
        "                    else:\n",
        "                        right_nu += shared_residual[i]\n",
        "                        right_de += shared_prob[i] * (1 - shared_prob[i])\n",
        "                        right_samples += 1\n",
        "            cuda.syncthreads()\n",
        "\n",
        "    if r < split.shape[0] and c < split.shape[1]:\n",
        "        if (left_samples < min_samples or right_samples < min_samples\n",
        "            or left_de < min_child_weight or right_de < min_child_weight ):\n",
        "            output[r, c] = np.nan\n",
        "        else:\n",
        "            left_sim = (left_nu ** 2) / (left_de + lambda_)\n",
        "            right_sim = (right_nu ** 2) / (right_de + lambda_)\n",
        "            gain = left_sim + right_sim - shared_root_gain[0]\n",
        "            output[r, c] = gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "34CoLI_eUzo2"
      },
      "outputs": [],
      "source": [
        "class Tree:\n",
        "    def __init__(self, max_depth = 3, min_samples = 1, min_child_weight = 1, lambda_ = 0, gamma = 0):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples = min_samples\n",
        "        self.min_child_weight = min_child_weight\n",
        "        self.lambda_ = lambda_\n",
        "        self.gamma = gamma\n",
        "        self.tree = {}\n",
        "        self.fbs_time = 0\n",
        "\n",
        "    def similarity(self, residual, probs):\n",
        "        nu = np.sum(residual) ** 2\n",
        "        de = np.sum(probs * (1 - probs)) + self.lambda_\n",
        "        return nu / de\n",
        "\n",
        "    def compute_output(self, residual, probs):\n",
        "        nu = np.sum(residual)\n",
        "        de = np.sum(probs * (1 - probs)) + self.lambda_\n",
        "        return nu / de\n",
        "\n",
        "    def split_data(self, X, feature_idx, split_value):\n",
        "        left_idx = X[:, feature_idx] <= split_value\n",
        "        right_idx = X[:, feature_idx] > split_value\n",
        "        return left_idx, right_idx\n",
        "\n",
        "    def find_best_split(self, X, residuals, probs):\n",
        "        best_gain = -np.inf\n",
        "        best_split_feature_idx = None\n",
        "        best_split_value = None\n",
        "\n",
        "        split_array = np.empty((X.shape[0] - 1, X.shape[1]))\n",
        "        block_size = (32, 32)\n",
        "        grid_split = (math.ceil(split_array.shape[1] / block_size[0]),\n",
        "                      math.ceil(split_array.shape[0] / block_size[1]))\n",
        "        compute_split_value_optimize[grid_split, block_size](np.sort(X, axis=0).astype(np.float64), split_array)\n",
        "\n",
        "        root_gain = self.similarity(residuals, probs)\n",
        "        gain_array = np.empty((split_array.shape[0], split_array.shape[1]))\n",
        "        grid_gain = (math.ceil(gain_array.shape[1] / block_size[0]),\n",
        "                     math.ceil(gain_array.shape[0] / block_size[1]))\n",
        "        compute_gain_optimize[grid_gain, block_size](split_array, gain_array, X, residuals,\n",
        "                                            probs, self.lambda_, self.min_child_weight, self.min_samples, root_gain)\n",
        "\n",
        "        gain_array[np.isnan(gain_array)] = -np.inf\n",
        "\n",
        "        if np.sum(gain_array == -np.inf) != (gain_array.shape[0] * gain_array.shape[1]):\n",
        "            tmp_gain = np.transpose(gain_array)\n",
        "            max_idx = np.unravel_index(tmp_gain.argmax(), tmp_gain.shape)\n",
        "            final_idx = (max_idx[1], max_idx[0])\n",
        "            best_split_feature_idx = final_idx[1]\n",
        "            best_gain = gain_array[final_idx]\n",
        "            best_split_value = split_array[final_idx]\n",
        "\n",
        "        if(best_gain - self.gamma < 0):\n",
        "            best_split_feature_idx = None\n",
        "            best_split_value = None\n",
        "\n",
        "        return best_split_feature_idx, best_split_value\n",
        "\n",
        "    def build_tree(self, X, residual, probs, depth):\n",
        "        if depth >= self.max_depth or len(X) <= self.min_samples:\n",
        "            return self.compute_output(residual, probs)\n",
        "\n",
        "        start = time.time()\n",
        "        split_feature_idx, split_value = self.find_best_split(X, residual, probs)\n",
        "        end = time.time()\n",
        "        self.fbs_time += (end - start)\n",
        "\n",
        "        if split_feature_idx is None:\n",
        "            return self.compute_output(residual, probs)\n",
        "\n",
        "        left_idx, right_idx = self.split_data(X, split_feature_idx, split_value)\n",
        "        left = self.build_tree(X[left_idx], residual[left_idx], probs[left_idx], depth + 1)\n",
        "        right = self.build_tree(X[right_idx], residual[right_idx], probs[right_idx], depth + 1)\n",
        "\n",
        "        self.tree = {\n",
        "            'split_feature_idx': split_feature_idx,\n",
        "            'split_value': split_value,\n",
        "            'left_child': left,\n",
        "            'right_child': right\n",
        "        }\n",
        "        return self.tree\n",
        "\n",
        "    def get_output(self, x, tree):\n",
        "        if isinstance(tree, dict):\n",
        "            split_feature_idx = tree['split_feature_idx']\n",
        "            split_value = tree['split_value']\n",
        "            if x[split_feature_idx] <= split_value:\n",
        "                return self.get_output(x, tree['left_child'])\n",
        "            else:\n",
        "                return self.get_output(x, tree['right_child'])\n",
        "        else:\n",
        "            return tree\n",
        "\n",
        "    def fit(self, X, residual, probs):\n",
        "        depth = 0\n",
        "        self.tree = self.build_tree(X, residual, probs, depth)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self.get_output(x, self.tree) for x in X])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzes5uuzVr8K"
      },
      "source": [
        "Các hàm `residual_optimize()` , `compute_logodds_optimize()`, `compute_prob_optimize()` sẽ cho mỗi thread block xử lý $2 * blockDim.x$ phần tử liên tiếp. Tất cả các thread trong mỗi block sẽ xử lý $blockDim.x$ phần tử đầu mảng, mỗi thread xử lý một phần tử. Sau đó tất cả các thread sẽ chuyển sang $blockDim.x$ phần tử sau của mảng, mỗi thread xử lý một phần tử."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sJayi1-KUzo5"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def residual_kernel(y_true, y_pred, residual):\n",
        "    i = cuda.blockIdx.x * cuda.blockDim.x * 2 + cuda.threadIdx.x\n",
        "    if i < residual.shape[0]:\n",
        "        residual[i] = y_true[i] - y_pred[i]\n",
        "    if i + cuda.blockDim.x < residual.shape[0]:\n",
        "        residual[i + cuda.blockDim.x] = y_true[i + cuda.blockDim.x] - y_pred[i + cuda.blockDim.x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PtykeywPUzo7"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def compute_logodds_kernel(p, log_odds):\n",
        "    i = cuda.blockIdx.x * cuda.blockDim.x * 2 + cuda.threadIdx.x\n",
        "    if i < log_odds.shape[0]:\n",
        "        log_odds[i] = math.log(p[i] / (1 - p[i]))\n",
        "    if i + cuda.blockDim.x < log_odds.shape[0]:\n",
        "        log_odds[i + cuda.blockDim.x] = math.log(p[i + cuda.blockDim.x] / (1 - p[i + cuda.blockDim.x]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Rn1IpYyBUzo8"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def compute_prob_kernel(logodds_p, p):\n",
        "    i = cuda.blockIdx.x * cuda.blockDim.x * 2 + cuda.threadIdx.x\n",
        "    if i < p.shape[0]:\n",
        "        p[i] = math.exp(logodds_p[i]) / (1 + math.exp(logodds_p[i]))\n",
        "    if i + cuda.blockDim.x < p.shape[0]:\n",
        "        p[i + cuda.blockDim.x] = math.exp(logodds_p[i + cuda.blockDim.x]) / (1 + math.exp(logodds_p[i + cuda.blockDim.x]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "E8SxzYNhUzo8"
      },
      "outputs": [],
      "source": [
        "class XGBoost:\n",
        "    def __init__(self, n_estimators, lr, lambda_ = 0, gamma = 0, min_child_weight = 1, max_depth = 3):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.lr = lr\n",
        "        self.initial_pred = 0.5\n",
        "        self.lambda_ = lambda_\n",
        "        self.min_child_weight = min_child_weight\n",
        "        self.max_depth = max_depth\n",
        "        self.gamma = gamma\n",
        "        self.models = []\n",
        "        self.fbs_time = 0\n",
        "        self.logodds_time = 0\n",
        "        self.residual_time = 0\n",
        "        self.predict_time = 0\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        p = np.full(len(y), self.initial_pred)\n",
        "        block_size = 32\n",
        "        grid_size = math.ceil(len(y) / 2 * block_size)\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            probs = np.copy(p)\n",
        "\n",
        "            residual = np.empty(len(y))\n",
        "            start = time.time()\n",
        "            residual_kernel[grid_size, block_size](y, p, residual)\n",
        "            end = time.time()\n",
        "            self.residual_time += (end - start)\n",
        "\n",
        "            model = Tree(lambda_ = self.lambda_, gamma = self.gamma, max_depth = self.max_depth, min_child_weight = self.min_child_weight)\n",
        "            model.fit(X, residual, probs)\n",
        "            self.fbs_time += model.fbs_time\n",
        "\n",
        "            log_odds = np.empty(len(y))\n",
        "            start = time.time()\n",
        "            compute_logodds_kernel[grid_size, block_size](p, log_odds)\n",
        "            end = time.time()\n",
        "            self.logodds_time += (end - start)\n",
        "\n",
        "            p = np.empty(len(y))\n",
        "            start = time.time()\n",
        "            logodds_p = log_odds + self.lr * model.predict(X)\n",
        "            compute_prob_kernel[grid_size, block_size](logodds_p, p)\n",
        "            end = time.time()\n",
        "            self.predict_time += (end - start)\n",
        "\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        pred = np.full(len(X), self.initial_pred)\n",
        "        block_size = 32\n",
        "        grid_size = math.ceil(len(X) / 2 * block_size)\n",
        "        for model in self.models:\n",
        "            log_odds = np.empty(len(X))\n",
        "            compute_logodds_kernel[grid_size, block_size](pred, log_odds)\n",
        "            logodds_p = log_odds + self.lr * model.predict(X)\n",
        "            pred = np.empty(len(X))\n",
        "            compute_prob_kernel[grid_size, block_size](logodds_p, pred)\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mgEyri5UUzo9"
      },
      "outputs": [],
      "source": [
        "class MultiClassifier:\n",
        "    def __init__(self, n_estimators = 3, lr = 0.3):\n",
        "        self.models = []\n",
        "        self.n_estimators = n_estimators\n",
        "        self.lr = lr\n",
        "        self.training_time = 0\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        start_time = time.time()\n",
        "        for label in np.unique(y):\n",
        "            binary_labels = (y == label).astype(int)\n",
        "            model = XGBoost(self.n_estimators, self.lr)\n",
        "            model.fit(X, binary_labels)\n",
        "            self.models.append(model)\n",
        "        end_time = time.time()\n",
        "        self.training_time += (end_time - start_time)\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = []\n",
        "        for model in self.models:\n",
        "            preds.append(model.predict_proba(X))\n",
        "        return np.argmax(preds, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0W8GRXIAUzo_"
      },
      "outputs": [],
      "source": [
        "train = np.load('train_data_3labels.npz', allow_pickle = True)\n",
        "X_train = train['data']\n",
        "y_train = train['label']\n",
        "\n",
        "test = np.load('test_data_3labels.npz', allow_pickle = True)\n",
        "X_test = test['data']\n",
        "y_test = test['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxlMmvMYUzpA",
        "outputId": "ddf403f1-7842-4a4b-aa2d-36314ebd60fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9466666666666667\n",
            "Total time: 2.447936534881592 seconds\n"
          ]
        }
      ],
      "source": [
        "binary_classifier = XGBoost(n_estimators = 3, lr = 0.3)\n",
        "start_time = time.time()\n",
        "binary_classifier.fit(X_train, (y_train == 0).astype(int))\n",
        "end_time = time.time()\n",
        "\n",
        "y_prob_pred = binary_classifier.predict_proba(X_test)\n",
        "binary_labels_pred = (y_prob_pred > 0.5).astype(int)\n",
        "binary_labels_test = (y_test == 0).astype(int)\n",
        "\n",
        "accuracy_binary = accuracy_score(binary_labels_test, binary_labels_pred)\n",
        "time_binary = end_time - start_time\n",
        "\n",
        "print('Accuracy:', accuracy_binary)\n",
        "print(f'Total time: {time_binary} seconds')\n",
        "\n",
        "#Song song\n",
        "#Accuracy: 0.9466666666666667\n",
        "#Total time: 4.270538568496704 seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoyRN4JPUzpA",
        "outputId": "57238669-d402-402f-f5f7-c314f6cb5351"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9566666666666667\n",
            "Total time: 7.6753692626953125 seconds\n"
          ]
        }
      ],
      "source": [
        "multi_classifier = MultiClassifier()\n",
        "multi_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = multi_classifier.predict(X_test)\n",
        "accuracy_3labels = accuracy_score(y_test, y_pred)\n",
        "time_3labels = multi_classifier.training_time\n",
        "\n",
        "print('Accuracy:', accuracy_3labels)\n",
        "print(f'Total time: {time_3labels} seconds')\n",
        "\n",
        "#Song song\n",
        "#Accuracy: 0.9566666666666667\n",
        "#Total time: 9.85064172744751 seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j2oONMSUzpB"
      },
      "outputs": [],
      "source": [
        "train = np.load('train_data.npz', allow_pickle = True)\n",
        "X_train = train['data']\n",
        "y_train = train['label']\n",
        "\n",
        "test = np.load('test_data.npz', allow_pickle = True)\n",
        "X_test = test['data']\n",
        "y_test = test['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJPIHXGiUzpC",
        "outputId": "cf90fb19-5bd9-41ea-e092-417bfba400ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.891\n",
            "Total time: 2633.7818756103516 seconds\n"
          ]
        }
      ],
      "source": [
        "multi_classifier = MultiClassifier(n_estimators = 35, lr = 0.3)\n",
        "multi_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = multi_classifier.predict(X_test)\n",
        "accuracy_10labels = accuracy_score(y_test, y_pred)\n",
        "time_10label = multi_classifier.training_time\n",
        "\n",
        "print('Accuracy:', accuracy_10labels)\n",
        "print(f'Total time: {time_10label} seconds')\n",
        "\n",
        "# Song song\n",
        "#Accuracy: 0.891\n",
        "#Total time: 2727.113727092743 seconds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lưu kết quả"
      ],
      "metadata": {
        "id": "zUwE7c_Nb2qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = pd.read_csv('result.csv')"
      ],
      "metadata": {
        "id": "ZzAz_46ka4hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df['Optimize_training_time'] = [time_binary, time_3labels, time_10label]\n",
        "result_df['Optimize_accuracy'] = [accuracy_binary, accuracy_3labels, accuracy_10labels]"
      ],
      "metadata": {
        "id": "TAzFfhZwa5eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.to_csv('result.csv', index = False)"
      ],
      "metadata": {
        "id": "_yQ-flFtbz3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Under sampling"
      ],
      "metadata": {
        "id": "M8a-isreawnQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5MsxlZCUzpC"
      },
      "outputs": [],
      "source": [
        "class MultiClassifier_2:\n",
        "    def __init__(self, n_estimators = 3, lr = 0.3):\n",
        "        self.models = []\n",
        "        self.n_estimators = n_estimators\n",
        "        self.lr = lr\n",
        "        self.training_time = 0.0\n",
        "\n",
        "    def under_sampling(self, X, y):\n",
        "        size = int((np.count_nonzero(y)) * 1.5)\n",
        "        random_idx = np.random.choice(len(np.where(y == 0)[0]), size = size)\n",
        "        idx = np.concatenate([np.where(y == 1)[0], random_idx])\n",
        "        return X[idx], y[idx]\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        start_time = time.time()\n",
        "        for label in np.unique(y):\n",
        "            binary_labels = (y == label).astype(int)\n",
        "            X_balance, y_balance = self.under_sampling(X, binary_labels)\n",
        "            model = XGBoost(self.n_estimators, self.lr)\n",
        "            model.fit(X_balance, y_balance)\n",
        "            self.models.append(model)\n",
        "        end_time = time.time()\n",
        "        self.training_time += (end_time - start_time)\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = []\n",
        "        for model in self.models:\n",
        "            preds.append(model.predict_proba(X))\n",
        "        return np.argmax(preds, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xllwC3IQBtD",
        "outputId": "58c245de-bf41-420b-82a5-9c345d84f908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.91\n",
            "Precision: [0.95145631 0.86792453 0.80733945 0.94059406 0.95348837 0.82300885\n",
            " 0.93258427 0.93069307 0.94230769 0.98863636]\n",
            "Total time: 587.247097492218 seconds\n"
          ]
        }
      ],
      "source": [
        "multi_classifier = MultiClassifier_2(n_estimators = 100, lr = 0.3)\n",
        "multi_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = multi_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average = None)\n",
        "training_time = multi_classifier.training_time\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('Precision:', precision)\n",
        "print(f'Total time: {training_time} seconds')\n",
        "\n",
        "#Song song\n",
        "#Accuracy: 0.903\n",
        "#Precision: [0.95789474 0.85981308 0.80357143 0.91428571 0.98823529 0.84466019\n",
        "# 0.875      0.91346154 0.94897959 0.95789474]\n",
        "#Total time: 650.0858426094055 seconds"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}