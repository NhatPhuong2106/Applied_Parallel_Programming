{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fn1qpOvC39Y"
      },
      "source": [
        "### Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yv9NEU6lsd0g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "from numba import cuda\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLA6JIvuC39u"
      },
      "source": [
        "### Cài đặt phiên bản XGBoost song song"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZQ8k3_aC39w"
      },
      "source": [
        "Thực hiện song song hoá một số hàm có khả năng song song nhằm triển khai XGBoost với thời gian thực thi ngắn hơn so với phiên bản tuần tự ban đầu trong khi mô hình vẫn duy trì độ chính xác chấp nhận được\n",
        "\n",
        "Mục tiêu chính là song song hoá thành công hàm `find_best_split()` vì đây là hàm chiếm hơn 90% tổng thời gian chạy XGBoost, nếu song song hoá tốt hàm này, thời gian thực thi tổng thể sẽ giảm đi rất nhiều. Ngoài ra, nhóm cũng sẽ tiến hành song song hoá một số hàm tính toán khác với mong muốn giảm thời gian huấn luyện đến mức thấp nhất."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsHZrc8Zsd0l"
      },
      "source": [
        "### Xét class **`Tree`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmdxanO8sd0x"
      },
      "source": [
        "**Song song hóa hàm `find_best_split()`**\n",
        "\n",
        "**Mô tả hàm**: `find_best_split()` là hàm tìm giá trị split sao cho gain của chúng khi rẽ nhánh đạt giá trị lớn nhất => đây là giá trị split tốt nhất dùng để rẽ nhánh.\n",
        "\n",
        "**Ý tưởng tuần tự**: Vét cạn tất cả trường hợp: Xét feature thứ i, tìm từng giá trị split theo feature i, tính gain và so sánh với `best_gain`, lặp lại đến hết và sau cùng lưu vị trí feature cùng với giá trị split và best_gain.\n",
        "\n",
        "**Ý tưởng song song**: Chia làm 2 hàm con:\n",
        "- `compute_split_value()`: tính tất cả giá trị split value, mỗi thread sẽ đảm nhiệm tính một giá trị split\n",
        "- `compute_gain()`: sau khi xác định được mảng giá trị split, với mỗi giá trị, ta tiến hành rẽ nhánh và tính gain.\n",
        "  \n",
        "Kết hợp với `np.argmax()` của thư viện numpy để tìm được giá trị split tốt nhất. Tương tự như ý tưởng tuần tự, ta lưu vị trí feature cùng với giá trị split và best_gain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxPM-kNmsd0y"
      },
      "outputs": [],
      "source": [
        "''' Hàm tính tất cả giá trị split value. Mỗi thread sẽ tìm split value của 2 giá trị liên tiếp\n",
        "    Nếu giá trị tại feature thứ i của mẫu A và B bằng nhau -> trả giá trị nan\n",
        "    Nếu giá trị tại feature thứ i của mẫu A và B khác nhau -> trả giá trị mean của 2 feature thuộc 2 mẫu\n",
        "    Tham số\n",
        "        input: ma trận dữ liệu X\n",
        "        output: ma trận split value\n",
        "\n",
        "    Trước khi đưa vào input sẽ được sort axis = 0 -> sort lại theo từng feature để dễ dàng tìm split value\n",
        "'''\n",
        "\n",
        "@cuda.jit\n",
        "def compute_split_value(input, output):\n",
        "    c, r = cuda.grid(2)\n",
        "    if r < output.shape[0] and c < output.shape[1]:\n",
        "        if input[r, c] != input[r + 1, c]:\n",
        "            split = (input[r, c] + input[r + 1, c]) / 2\n",
        "            output[r, c] = split\n",
        "        else:\n",
        "            output[r, c] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2COuPu6sd0z"
      },
      "outputs": [],
      "source": [
        "''' Tính gain ứng với giá trị split. Một thread sẽ thực hiện việc chia data thành 2 bên left right & tính gain\n",
        "    Với mỗi giá trị split:\n",
        "    Nếu split value là nan thì bỏ qua, trả kết quả gain = nan\n",
        "    Nếu split value khác nan: tính residual và prob của 2 phần left right, xét tính hợp lệ của cover, tính gain\n",
        "    Trả kết quả về\n",
        "'''\n",
        "\n",
        "@cuda.jit\n",
        "def compute_gain(split, output, X, residuals, p, lambda_, min_child_weight, min_samples, root_gain):\n",
        "    c, r = cuda.grid(2)\n",
        "    if r < split.shape[0] and c < split.shape[1]:\n",
        "        if split[r, c] != np.nan:\n",
        "            left_nu, right_nu, left_de, right_de, left_samples, right_samples = 0, 0, 0, 0, 0, 0\n",
        "            for i in range(X.shape[0]):\n",
        "                if X[i, c] <= split[r, c]:\n",
        "                    left_nu += residuals[i]\n",
        "                    left_de += p[i] * (1 - p[i])\n",
        "                    left_samples += 1\n",
        "                else:\n",
        "                    right_nu += residuals[i]\n",
        "                    right_de += p[i] * (1 - p[i])\n",
        "                    right_samples += 1\n",
        "            if (left_de < min_child_weight or right_de < min_child_weight\n",
        "                or left_samples < min_samples or right_samples < min_samples):\n",
        "                output[r,c] = np.nan\n",
        "            else:\n",
        "                left_sim = (left_nu ** 2) / (left_de + lambda_)\n",
        "                right_sim = (right_nu ** 2) / (right_de + lambda_)\n",
        "                gain = left_sim + right_sim - root_gain\n",
        "                output[r,c] = gain\n",
        "        else:\n",
        "            output[r,c] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CbcM2IUsd02"
      },
      "outputs": [],
      "source": [
        "class Tree:\n",
        "    def __init__(self, max_depth = 3, min_samples = 1, min_child_weight = 1, lambda_ = 0, gamma = 0):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples = min_samples\n",
        "        self.min_child_weight = min_child_weight\n",
        "        self.lambda_ = lambda_\n",
        "        self.gamma = gamma\n",
        "        self.tree = {}\n",
        "        self.fbs_time = 0\n",
        "\n",
        "    def similarity(self, residual, probs):\n",
        "        nu = np.sum(residual) ** 2\n",
        "        de = np.sum(probs * (1 - probs)) + self.lambda_\n",
        "        return nu / de\n",
        "\n",
        "    def compute_output(self, residual, probs):\n",
        "        nu = np.sum(residual)\n",
        "        de = np.sum(probs * (1 - probs)) + self.lambda_\n",
        "        return nu / de\n",
        "\n",
        "    def split_data(self, X, feature_idx, split_value):\n",
        "        left_idx = X[:, feature_idx] <= split_value\n",
        "        right_idx = X[:, feature_idx] > split_value\n",
        "        return left_idx, right_idx\n",
        "\n",
        "    ''' Find_best_split được song song hóa sử dụng 2 hàm con. Các bước:\n",
        "        1. Tạo mảng split array - các giá trị để chia sample thành 2 bên trái phải\n",
        "            Các giá trị nan, tượng trưng cho việc đã có trường hợp split này\n",
        "        2. Tính gain cho mỗi trường hợp split\n",
        "        3. Gán các giá trị nan thành -inf để loại trường hợp nan\n",
        "        4. Transpose mảng gain:\n",
        "            + Do phiên bản tuần tự dò tìm max đi theo từng cột\n",
        "            + Phiên bản song song dùng np.argmax() do tìm max theo từng hàng\n",
        "            + Vì thế cần transpose mảng gain để cả 2 phiên bản đều tìm cùng 1 kết quả\n",
        "        5. Dùng np.argmax() để tìm được vị trí có gain lớn nhất\n",
        "            Dùng kết quả để xác định lại vị trí thì phải đảo ngược result = (max_idx[1], max_idx[0])\n",
        "        6. Xem xét tỉa cây dựa trên gamma\n",
        "    '''\n",
        "    def find_best_split(self, X, residuals, probs):\n",
        "        best_gain = -np.inf\n",
        "        best_split_feature_idx = None\n",
        "        best_split_value = None\n",
        "\n",
        "        split_array = np.empty((X.shape[0] - 1, X.shape[1]))\n",
        "        block_size = (32, 32)\n",
        "        grid_split = (math.ceil(split_array.shape[1] / block_size[0]),\n",
        "                      math.ceil(split_array.shape[0] / block_size[1]))\n",
        "        compute_split_value[grid_split, block_size](np.sort(X, axis=0), split_array)\n",
        "\n",
        "        root_gain = self.similarity(residuals, probs)\n",
        "        gain_array = np.empty((split_array.shape[0], split_array.shape[1]))\n",
        "        grid_gain = (math.ceil(gain_array.shape[1] / block_size[0]),\n",
        "                     math.ceil(gain_array.shape[0] / block_size[1]))\n",
        "        compute_gain[grid_gain, block_size](split_array, gain_array, X, residuals,\n",
        "                                            probs, self.lambda_, self.min_child_weight, self.min_samples, root_gain)\n",
        "\n",
        "        gain_array[np.isnan(gain_array)] = -np.inf\n",
        "\n",
        "        if np.sum(gain_array == -np.inf) != (gain_array.shape[0] * gain_array.shape[1]):\n",
        "            tmp_gain = np.transpose(gain_array)\n",
        "            max_idx = np.unravel_index(tmp_gain.argmax(), tmp_gain.shape)\n",
        "            final_idx = (max_idx[1], max_idx[0])\n",
        "            best_split_feature_idx = final_idx[1]\n",
        "            best_gain = gain_array[final_idx]\n",
        "            best_split_value = split_array[final_idx]\n",
        "\n",
        "        if(best_gain - self.gamma < 0):\n",
        "            best_split_feature_idx = None\n",
        "            best_split_value = None\n",
        "\n",
        "        return best_split_feature_idx, best_split_value\n",
        "\n",
        "    def build_tree(self, X, residual, probs, depth):\n",
        "        if depth >= self.max_depth or len(X) <= self.min_samples:\n",
        "            return self.compute_output(residual, probs)\n",
        "\n",
        "        start = time.time()\n",
        "        split_feature_idx, split_value = self.find_best_split(X, residual, probs)\n",
        "        end = time.time()\n",
        "        self.fbs_time += (end - start)\n",
        "\n",
        "        if split_feature_idx is None:\n",
        "            return self.compute_output(residual, probs)\n",
        "\n",
        "        left_idx, right_idx = self.split_data(X, split_feature_idx, split_value)\n",
        "        left = self.build_tree(X[left_idx], residual[left_idx], probs[left_idx], depth + 1)\n",
        "        right = self.build_tree(X[right_idx], residual[right_idx], probs[right_idx], depth + 1)\n",
        "\n",
        "        self.tree = {\n",
        "            'split_feature_idx': split_feature_idx,\n",
        "            'split_value': split_value,\n",
        "            'left_child': left,\n",
        "            'right_child': right\n",
        "        }\n",
        "        return self.tree\n",
        "\n",
        "    def get_output(self, x, tree):\n",
        "        if isinstance(tree, dict):\n",
        "            split_feature_idx = tree['split_feature_idx']\n",
        "            split_value = tree['split_value']\n",
        "            if x[split_feature_idx] <= split_value:\n",
        "                return self.get_output(x, tree['left_child'])\n",
        "            else:\n",
        "                return self.get_output(x, tree['right_child'])\n",
        "        else:\n",
        "            return tree\n",
        "\n",
        "    def fit(self, X, residual, probs):\n",
        "        depth = 0\n",
        "        self.tree = self.build_tree(X, residual, probs, depth)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self.get_output(x, self.tree) for x in X])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVCi2wapC398"
      },
      "source": [
        "### Xét class **`XGBoost`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLKL_h1hC39-"
      },
      "source": [
        "**Song song hóa hàm `residual()`**\n",
        "\n",
        "**Mô tả hàm**: `residual()` là hàm tính toán sự chênh lệch giữa y thực tế và kết quả dự đoán\n",
        "\n",
        "**Ý tưởng tuần tự**: Sử dụng thư viện numpy để tính giá trị residual  \n",
        "\n",
        "**Ý tưởng song song**: Mỗi một thread sẽ được dùng để tính giá trị residual của một mẫu (sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ9WKmMSC39_"
      },
      "outputs": [],
      "source": [
        "''' Hàm tính toán sự chênh lệch giữa y thực tế và kết quả dự đoán\n",
        "    y_true, y_pred lần lượt là giá trị y thực tế và kết quả dự đoán\n",
        "    residual là kết quả chênh lệch giữa y_true và y_pred\n",
        "'''\n",
        "\n",
        "@cuda.jit\n",
        "def residual_kernel(y_true, y_pred, residual):\n",
        "    i = cuda.grid(1)\n",
        "    if i < residual.shape[0]:\n",
        "        residual[i] = y_true[i] - y_pred[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egDZ8MTvC3-A"
      },
      "source": [
        "**Song song hóa hàm `compute_logodds()`**\n",
        "\n",
        "**Mô tả hàm**: compute_logodds() là hàm chuyển giá trị xác suất p thành giá trị log(odds)\n",
        "\n",
        "**Ý tưởng tuần tự**: Sử dụng thư viện numpy để tính giá trị log(odds)\n",
        "\n",
        "**Ý tưởng song song**: Mỗi một thread sẽ được dùng để tính giá trị log(odds) của một mẫu (sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsleN1ipC3-B"
      },
      "outputs": [],
      "source": [
        "''' Hàm chuyển giá trị xác suất p thành giá trị log(odds)\n",
        "    p: giá trị xác suất ban đầu\n",
        "    log_odds: giá trị sau khi chuyển\n",
        "'''\n",
        "\n",
        "@cuda.jit\n",
        "def compute_logodds_kernel(p, log_odds):\n",
        "    i = cuda.grid(1)\n",
        "    if i < log_odds.shape[0]:\n",
        "        log_odds[i] = math.log(p[i] / (1 - p[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H44S_8PpC3-C"
      },
      "source": [
        "**Song song hóa hàm `compute_prob()`**\n",
        "\n",
        "**Mô tả hàm**: compute_prob() là hàm chuyển giá trị log(odds) thành giá trị xác suất p   \n",
        "\n",
        "**Ý tưởng tuần tự**: Sử dụng thư viện numpy để tính giá trị xác suất p\n",
        "\n",
        "**Ý tưởng song song**: Mỗi một thread sẽ được dùng để tính giá trị xác suất p của một mẫu (sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKvJUVlQC3-D"
      },
      "outputs": [],
      "source": [
        "''' Hàm chuyển giá trị log(odds) thành giá trị xác suất p\n",
        "    logodds_p: giá trị log(odds) ban đầu\n",
        "    p: giá trị xác suất p sau khi chuyển\n",
        "'''\n",
        "\n",
        "@cuda.jit\n",
        "def compute_prob_kernel(logodds_p, p):\n",
        "    i = cuda.grid(1)\n",
        "    if i < p.shape[0]:\n",
        "        p[i] = math.exp(logodds_p[i]) / (1 + math.exp(logodds_p[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4UTcp4Ssd06"
      },
      "outputs": [],
      "source": [
        "class XGBoost:\n",
        "    def __init__(self, n_estimators, lr, lambda_ = 1e-7, gamma = 0, min_child_weight = 1, max_depth = 3):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.lr = lr\n",
        "        self.initial_pred = 0.5\n",
        "        self.lambda_ = lambda_\n",
        "        self.min_child_weight = min_child_weight\n",
        "        self.max_depth = max_depth\n",
        "        self.gamma = gamma\n",
        "        self.models = []\n",
        "        self.fbs_time = 0\n",
        "        self.logodds_time = 0\n",
        "        self.residual_time = 0\n",
        "        self.predict_time = 0\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        p = np.full(len(y), self.initial_pred)\n",
        "        block_size = 32\n",
        "        grid_size = math.ceil(len(y)/block_size)\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            probs = np.copy(p)\n",
        "\n",
        "            residual = np.empty(len(y))\n",
        "            start = time.time()\n",
        "            residual_kernel[grid_size, block_size](y, p, residual)\n",
        "            end = time.time()\n",
        "            self.residual_time += (end - start)\n",
        "\n",
        "            model = Tree(lambda_ = self.lambda_, gamma = self.gamma, max_depth = self.max_depth, min_child_weight = self.min_child_weight)\n",
        "            model.fit(X, residual, probs)\n",
        "            self.fbs_time += model.fbs_time\n",
        "\n",
        "            log_odds = np.empty(len(y))\n",
        "            start = time.time()\n",
        "            compute_logodds_kernel[grid_size, block_size](p, log_odds)\n",
        "            end = time.time()\n",
        "            self.logodds_time += (end - start)\n",
        "\n",
        "            p = np.empty(len(y))\n",
        "            start = time.time()\n",
        "            logodds_p = log_odds + self.lr * model.predict(X)\n",
        "            compute_prob_kernel[grid_size, block_size](logodds_p, p)\n",
        "            end = time.time()\n",
        "            self.predict_time += (end - start)\n",
        "\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        pred = np.full(len(X), self.initial_pred)\n",
        "        block_size = 32\n",
        "        grid_size = math.ceil(len(X)/block_size)\n",
        "        for model in self.models:\n",
        "            log_odds = np.empty(len(X))\n",
        "            compute_logodds_kernel[grid_size, block_size](pred, log_odds)\n",
        "            logodds_p = log_odds + self.lr * model.predict(X)\n",
        "            pred = np.empty(len(X))\n",
        "            compute_prob_kernel[grid_size, block_size](logodds_p, pred)\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqHectJnC3-F"
      },
      "source": [
        "### Xây dựng mô hình đa lớp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byyfoCs9C3-G"
      },
      "outputs": [],
      "source": [
        "class MultiClassifier:\n",
        "    def __init__(self, n_estimators = 3, lr = 0.3):\n",
        "        self.models = []\n",
        "        self.n_estimators = n_estimators\n",
        "        self.lr = lr\n",
        "        self.training_time = 0\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        start_time = time.time()\n",
        "        for label in np.unique(y):\n",
        "            binary_labels = (y == label).astype(int)\n",
        "            model = XGBoost(self.n_estimators, self.lr)\n",
        "            model.fit(X, binary_labels)\n",
        "            self.models.append(model)\n",
        "        end_time = time.time()\n",
        "        self.training_time += (end_time - start_time)\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = []\n",
        "        for model in self.models:\n",
        "            preds.append(model.predict_proba(X))\n",
        "        return np.argmax(preds, axis = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVZR39xNC3-H"
      },
      "source": [
        "### Chạy mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj8-MmQKsd09"
      },
      "outputs": [],
      "source": [
        "train = np.load('train_data_3labels.npz', allow_pickle = True)\n",
        "X_train = train['data']\n",
        "y_train = train['label']\n",
        "\n",
        "test = np.load('test_data_3labels.npz', allow_pickle = True)\n",
        "X_test = test['data']\n",
        "y_test = test['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dafacnzqE9FR"
      },
      "source": [
        "#### Binary classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc3rcJqvC3-I",
        "outputId": "bc1caf64-17fb-4cdd-fff8-3633e2e2800b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9466666666666667\n",
            "Total time: 4.270538568496704 seconds\n"
          ]
        }
      ],
      "source": [
        "binary_classifier = XGBoost(n_estimators = 3, lr = 0.3)\n",
        "start_time = time.time()\n",
        "binary_classifier.fit(X_train, (y_train == 0).astype(int))\n",
        "end_time = time.time()\n",
        "\n",
        "y_prob_pred = binary_classifier.predict_proba(X_test)\n",
        "binary_labels_pred = (y_prob_pred > 0.5).astype(int)\n",
        "binary_labels_test = (y_test == 0).astype(int)\n",
        "\n",
        "accuracy_binary = accuracy_score(binary_labels_test, binary_labels_pred)\n",
        "time_binary = end_time - start_time\n",
        "\n",
        "print('Accuracy:', accuracy_binary)\n",
        "print(f'Total time: {time_binary} seconds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f5EXBZXFIOv"
      },
      "source": [
        "#### Multi classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_c7tfOkC3-J",
        "outputId": "aeeb1835-751b-42fe-a57c-47c2ed9acaa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9566666666666667\n",
            "Total time: 7.5918519496917725 seconds\n"
          ]
        }
      ],
      "source": [
        "multi_classifier = MultiClassifier()\n",
        "multi_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = multi_classifier.predict(X_test)\n",
        "accuracy_3labels = accuracy_score(y_test, y_pred)\n",
        "time_3labels = multi_classifier.training_time\n",
        "\n",
        "print('Accuracy:', accuracy_3labels)\n",
        "print(f'Total time: {time_3labels} seconds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQa7MAlSFWEG"
      },
      "source": [
        "#### Multi classification trên tập dữ liệu hoàn chỉnh (10 lớp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKLCBznnEk1q"
      },
      "outputs": [],
      "source": [
        "train = np.load('train_data.npz', allow_pickle = True)\n",
        "X_train = train['data']\n",
        "y_train = train['label']\n",
        "\n",
        "test = np.load('test_data.npz', allow_pickle = True)\n",
        "X_test = test['data']\n",
        "y_test = test['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZp0nrdsekPD",
        "outputId": "85e0c29e-d0ec-4dd6-e84f-32be4f50ff97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.891\n",
            "Total time: 2727.113727092743 seconds\n"
          ]
        }
      ],
      "source": [
        "multi_classifier = MultiClassifier(n_estimators = 35, lr = 0.3)\n",
        "multi_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = multi_classifier.predict(X_test)\n",
        "accuracy_10labels = accuracy_score(y_test, y_pred)\n",
        "time_10label = multi_classifier.training_time\n",
        "\n",
        "print('Accuracy:', accuracy_10labels)\n",
        "print(f'Total time: {time_10label} seconds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2aS560MIzoi"
      },
      "source": [
        "### Lưu kết quả"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIUzBmmkI2ge"
      },
      "outputs": [],
      "source": [
        "result_df = pd.read_csv('result.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_df['Parallel_training_time'] = [time_binary, time_3labels, time_10label]\n",
        "result_df['Parallel_accuracy'] = [accuracy_binary, accuracy_3labels, accuracy_10labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6BPL8GpKLNi"
      },
      "outputs": [],
      "source": [
        "result_df.to_csv('result.csv', index = False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
