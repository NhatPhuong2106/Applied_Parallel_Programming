{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Yv9NEU6lsd0g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "from numba import cuda\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cài đặt phiên bản XGBoost song song"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thực hiện song song hoá một số hàm có khả năng song song nhằm triển khai XGBoost với thời gian thực thi ngắn hơn so với phiên bản tuần tự ban đầu trong khi mô hình vẫn duy trì độ chính xác chấp nhận được\n",
        "\n",
        "Mục tiêu chính là song song hoá thành công hàm `find_best_split()` vì đây là hàm chiếm hơn 90% tổng thời gian chạy XGBoost, nếu song song hoá tốt hàm này, thời gian thực thi tổng thể sẽ giảm đi rất nhiều. Ngoài ra, nhóm cũng sẽ tiến hành song song hoá một số hàm tính toán khác với mong muốn giảm thời gian huấn luyện đến mức thấp nhất."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsHZrc8Zsd0l"
      },
      "source": [
        "### Xét class **`Tree`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmdxanO8sd0x"
      },
      "source": [
        "**Song song hóa hàm `find_best_split()`**\n",
        "\n",
        "**Mô tả hàm**: `find_best_split()` là hàm tìm giá trị split sao cho gain của chúng khi rẽ nhánh đạt giá trị lớn nhất => đây là giá trị split tốt nhất dùng để rẽ nhánh.\n",
        "\n",
        "**Ý tưởng tuần tự**: Vét cạn tất cả trường hợp: Xét feature thứ i, tìm từng giá trị split theo feature i, tính gain và so sánh với `best_gain`, lặp lại đến hết và sau cùng lưu vị trí feature cùng với giá trị split và best_gain.\n",
        "\n",
        "**Ý tưởng song song**: Chia làm 2 hàm con:\n",
        "- `compute_split_value()`: tính tất cả giá trị split value, mỗi thread sẽ đảm nhiệm tính một giá trị split\n",
        "- `compute_gain()`: sau khi xác định được mảng giá trị split, với mỗi giá trị, ta tiến hành rẽ nhánh và tính gain.\n",
        "  \n",
        "Kết hợp với `np.argmax()` của thư viện numpy để tìm được giá trị split tốt nhất. Tương tự như ý tưởng tuần tự, ta lưu vị trí feature cùng với giá trị split và best_gain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PxPM-kNmsd0y"
      },
      "outputs": [],
      "source": [
        "''' Hàm tính tất cả giá trị split value. Mỗi thread sẽ tìm split value của 2 giá trị liên tiếp\n",
        "    Nếu giá trị tại feature thứ i của mẫu A và B bằng nhau -> trả giá trị nan\n",
        "    Nếu giá trị tại feature thứ i của mẫu A và B khác nhau -> trả giá trị mean của 2 feature thuộc 2 mẫu\n",
        "    Tham số\n",
        "        input: ma trận dữ liệu X\n",
        "        output: ma trận split value\n",
        "\n",
        "    Trước khi đưa vào input sẽ được sort axis = 0 -> sort lại theo từng feature để dễ dàng tìm split value\n",
        "'''\n",
        "\n",
        "@cuda.jit\n",
        "def compute_split_value(input, output):\n",
        "    c, r = cuda.grid(2)\n",
        "    if r < output.shape[0] and c < output.shape[1]:\n",
        "        if input[r, c] != input[r + 1, c]:\n",
        "            split = (input[r, c] + input[r + 1, c]) / 2\n",
        "            output[r, c] = split\n",
        "        else:\n",
        "            output[r, c] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_2COuPu6sd0z"
      },
      "outputs": [],
      "source": [
        "''' Tính gain ứng với giá trị split. Một thread sẽ thực hiện việc chia data thành 2 bên left right & tính gain\n",
        "    Với mỗi giá trị split:\n",
        "    Nếu split value là nan thì bỏ qua, trả kết quả gain = nan\n",
        "    Nếu split value khác nan: tính residual và prob của 2 phần left right, xét tính hợp lệ của cover, tính gain\n",
        "    Trả kết quả về\n",
        "'''\n",
        "\n",
        "@cuda.jit\n",
        "def compute_gain(split, output, X, residuals, p, lambda_, min_child_weight, min_samples, root_gain):\n",
        "    c, r = cuda.grid(2)\n",
        "    if r < split.shape[0] and c < split.shape[1]:\n",
        "        if split[r, c] != np.nan:\n",
        "            left_nu, right_nu, left_de, right_de, left_samples, right_samples = 0, 0, 0, 0, 0, 0\n",
        "            for i in range(X.shape[0]):\n",
        "                if X[i, c] <= split[r, c]:\n",
        "                    left_nu += residuals[i]\n",
        "                    left_de += p[i] * (1 - p[i])\n",
        "                    left_samples += 1\n",
        "                else:\n",
        "                    right_nu += residuals[i]\n",
        "                    right_de += p[i] * (1 - p[i])\n",
        "                    right_samples += 1\n",
        "            if (left_de < min_child_weight or right_de < min_child_weight\n",
        "                or left_samples < min_samples or right_samples < min_samples):\n",
        "                output[r,c] = np.nan\n",
        "            else:\n",
        "                left_sim = (left_nu ** 2) / (left_de + lambda_)\n",
        "                right_sim = (right_nu ** 2) / (right_de + lambda_)\n",
        "                gain = left_sim + right_sim - root_gain\n",
        "                output[r,c] = gain\n",
        "        else:\n",
        "            output[r,c] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8CbcM2IUsd02"
      },
      "outputs": [],
      "source": [
        "class Tree:\n",
        "    def __init__(self, max_depth = 3, min_samples = 1, min_child_weight = 1, lambda_ = 0, gamma = 0):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples = min_samples\n",
        "        self.min_child_weight = min_child_weight\n",
        "        self.lambda_ = lambda_\n",
        "        self.gamma = gamma\n",
        "        self.tree = {}\n",
        "        self.fbs_time = 0\n",
        "\n",
        "    def similarity(self, residual, probs):\n",
        "        nu = np.sum(residual) ** 2\n",
        "        de = np.sum(probs * (1 - probs)) + self.lambda_\n",
        "        return nu / de\n",
        "\n",
        "    def compute_output(self, residual, probs):\n",
        "        nu = np.sum(residual)\n",
        "        de = np.sum(probs * (1 - probs)) + self.lambda_\n",
        "        return nu / de\n",
        "\n",
        "    def split_data(self, X, feature_idx, split_value):\n",
        "        left_idx = X[:, feature_idx] <= split_value\n",
        "        right_idx = X[:, feature_idx] > split_value\n",
        "        return left_idx, right_idx\n",
        "\n",
        "    ''' Find_best_split được song song hóa sử dụng 2 hàm con. Các bước:\n",
        "        1. Tạo mảng split array - các giá trị để chia sample thành 2 bên trái phải\n",
        "            Các giá trị nan, tượng trưng cho việc đã có trường hợp split này\n",
        "        2. Tính gain cho mỗi trường hợp split\n",
        "        3. Gán các giá trị nan thành -inf để loại trường hợp nan\n",
        "        4. Transpose mảng gain:\n",
        "            + Do phiên bản tuần tự dò tìm max đi theo từng cột\n",
        "            + Phiên bản song song dùng np.argmax() do tìm max theo từng hàng\n",
        "            + Vì thế cần transpose mảng gain để cả 2 phiên bản đều tìm cùng 1 kết quả\n",
        "        5. Dùng np.argmax() để tìm được vị trí có gain lớn nhất\n",
        "            Dùng kết quả để xác định lại vị trí thì phải đảo ngược result = (max_idx[1], max_idx[0])\n",
        "        6. Xem xét tỉa cây dựa trên gamma\n",
        "    '''\n",
        "    def find_best_split(self, X, residuals, probs):\n",
        "        best_gain = -np.inf\n",
        "        best_split_feature_idx = None\n",
        "        best_split_value = None\n",
        "\n",
        "        split_array = np.empty((X.shape[0] - 1, X.shape[1]))\n",
        "        block_size = (32, 32)\n",
        "        grid_split = (math.ceil(split_array.shape[1] / block_size[0]),\n",
        "                      math.ceil(split_array.shape[0] / block_size[1]))\n",
        "        compute_split_value[grid_split, block_size](np.sort(X, axis=0), split_array)\n",
        "\n",
        "        root_gain = self.similarity(residuals, probs)\n",
        "        gain_array = np.empty((split_array.shape[0], split_array.shape[1]))\n",
        "        grid_gain = (math.ceil(gain_array.shape[1] / block_size[0]),\n",
        "                     math.ceil(gain_array.shape[0] / block_size[1]))\n",
        "        compute_gain[grid_gain, block_size](split_array, gain_array, X, residuals, \n",
        "                                            probs, self.lambda_, self.min_child_weight, self.min_samples, root_gain)\n",
        "\n",
        "        gain_array[np.isnan(gain_array)] = -np.inf\n",
        "\n",
        "        if np.sum(gain_array == -np.inf) != (gain_array.shape[0] * gain_array.shape[1]):\n",
        "            tmp_gain = np.transpose(gain_array)\n",
        "            max_idx = np.unravel_index(tmp_gain.argmax(), tmp_gain.shape)\n",
        "            final_idx = (max_idx[1], max_idx[0])\n",
        "            best_split_feature_idx = final_idx[1]\n",
        "            best_gain = gain_array[final_idx]\n",
        "            best_split_value = split_array[final_idx]\n",
        "\n",
        "        if(best_gain - self.gamma < 0):\n",
        "            best_split_feature_idx = None\n",
        "            best_split_value = None\n",
        "\n",
        "        return best_split_feature_idx, best_split_value\n",
        "\n",
        "    def build_tree(self, X, residual, probs, depth):\n",
        "        if depth >= self.max_depth or len(X) <= self.min_samples:\n",
        "            return self.compute_output(residual, probs)\n",
        "\n",
        "        start = time.time()\n",
        "        split_feature_idx, split_value = self.find_best_split(X, residual, probs)\n",
        "        end = time.time()\n",
        "        self.fbs_time += (end - start)\n",
        "\n",
        "        if split_feature_idx is None:\n",
        "            return self.compute_output(residual, probs)\n",
        "\n",
        "        left_idx, right_idx = self.split_data(X, split_feature_idx, split_value)\n",
        "        left = self.build_tree(X[left_idx], residual[left_idx], probs[left_idx], depth + 1)\n",
        "        right = self.build_tree(X[right_idx], residual[right_idx], probs[right_idx], depth + 1)\n",
        "\n",
        "        self.tree = {\n",
        "            'split_feature_idx': split_feature_idx,\n",
        "            'split_value': split_value,\n",
        "            'left_child': left,\n",
        "            'right_child': right\n",
        "        }\n",
        "        return self.tree\n",
        "\n",
        "    def get_output(self, x, tree):\n",
        "        if isinstance(tree, dict):\n",
        "            split_feature_idx = tree['split_feature_idx']\n",
        "            split_value = tree['split_value']\n",
        "            if x[split_feature_idx] <= split_value:\n",
        "                return self.get_output(x, tree['left_child'])\n",
        "            else:\n",
        "                return self.get_output(x, tree['right_child'])\n",
        "        else:\n",
        "            return tree\n",
        "\n",
        "    def fit(self, X, residual, probs):\n",
        "        depth = 0\n",
        "        self.tree = self.build_tree(X, residual, probs, depth)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self.get_output(x, self.tree) for x in X])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Xét class **`XGBoost`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "M4UTcp4Ssd06"
      },
      "outputs": [],
      "source": [
        "class XGBoost:\n",
        "    def __init__(self, n_estimators, lr, lambda_ = 1e-7, gamma = 0, min_child_weight = 1, max_depth = 3):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.lr = lr\n",
        "        self.initial_pred = 0.5\n",
        "        self.lambda_ = lambda_\n",
        "        self.min_child_weight = min_child_weight\n",
        "        self.max_depth = max_depth\n",
        "        self.gamma = gamma\n",
        "        self.models = []\n",
        "        self.fbs_time = 0\n",
        "        self.logodds_time = 0\n",
        "        self.residual_time = 0\n",
        "        self.logodds_predict_time = 0\n",
        "        self.pred_time = 0\n",
        "\n",
        "    #Turn probability into log odds value\n",
        "    def compute_logodds(self, p):\n",
        "        return np.log(p / (1 - p))\n",
        "\n",
        "    #Caclculate pseudo residuals\n",
        "    def residual(self, y_true, y_pred):\n",
        "        return (y_true - y_pred)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        p = np.full(len(y), self.initial_pred)\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            probs = np.copy(p)\n",
        "            start = time.time()\n",
        "            residual = self.residual(y, p)\n",
        "            end = time.time()\n",
        "            self.residual_time += (end - start)\n",
        "\n",
        "            model = Tree(lambda_ = self.lambda_, gamma = self.gamma, max_depth = self.max_depth, min_child_weight = self.min_child_weight)\n",
        "            model.fit(X, residual, probs)\n",
        "            self.fbs_time += model.fbs_time\n",
        "\n",
        "            start = time.time()\n",
        "            log_odds = self.compute_logodds(p)\n",
        "            end = time.time()\n",
        "            self.logodds_time += (end - start)\n",
        "\n",
        "            start = time.time()\n",
        "            logodds_p = log_odds + self.lr * model.predict(X)\n",
        "            end = time.time()\n",
        "            self.logodds_predict_time += (end - start)\n",
        "\n",
        "            start = time.time()\n",
        "            #Change log odds value back to probability\n",
        "            p = np.exp(logodds_p) / (1 + np.exp(logodds_p))\n",
        "            end = time.time()\n",
        "            self.pred_time += (end - start)\n",
        "\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        pred = np.full(len(X), self.initial_pred)\n",
        "        for model in self.models:\n",
        "            logodds_p = self.compute_logodds(pred) + self.lr * model.predict(X)\n",
        "            pred = np.exp(logodds_p) / (1 + np.exp(logodds_p))\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Xây dựng mô hình đa lớp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiClassifier:\n",
        "    def __init__(self, n_estimators = 3, lr = 0.3):\n",
        "        self.models = []\n",
        "        self.n_estimators = n_estimators\n",
        "        self.lr = lr\n",
        "        self.training_time = 0\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        start_time = time.time()\n",
        "        for label in np.unique(y):\n",
        "            binary_labels = (y == label).astype(int)\n",
        "            model = XGBoost(self.n_estimators, self.lr)\n",
        "            model.fit(X, binary_labels)\n",
        "            self.models.append(model)\n",
        "        end_time = time.time()\n",
        "        self.training_time += (end_time - start_time)\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = []\n",
        "        for model in self.models:\n",
        "            preds.append(model.predict_proba(X))\n",
        "        return np.argmax(preds, axis = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Chạy mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jj8-MmQKsd09"
      },
      "outputs": [],
      "source": [
        "train = np.load('train_data_3labels.npz', allow_pickle = True)\n",
        "X_train = train['data']\n",
        "y_train = train['label']\n",
        "\n",
        "test = np.load('test_data_3labels.npz', allow_pickle = True)\n",
        "X_test = test['data']\n",
        "y_test = test['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt4RzAp8sd0_",
        "outputId": "baeb0d4a-3a4d-4bea-e3bd-7fb44e420920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9566666666666667\n",
            "Total time: 7.306426525115967 seconds\n",
            "Find_best_split function time: 7.161401271820068 seconds\n"
          ]
        }
      ],
      "source": [
        "multi_classifier = MultiClassifier()\n",
        "multi_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = multi_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print(f'Total time: {multi_classifier.training_time} seconds')\n",
        "fbs_time = sum([multi_classifier.models[i].fbs_time for i in range(len(multi_classifier.models))])\n",
        "print(f'Find_best_split function time: {fbs_time} seconds')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
