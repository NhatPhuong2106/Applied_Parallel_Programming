{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jjLREnOAUH6r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NWGpSJ29bVr4"
      },
      "outputs": [],
      "source": [
        "class Tree:\n",
        "    def __init__(self, max_depth = 3, min_samples = 1, min_child_weight = 1, lambda_ = 0, gamma = 0):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples = min_samples\n",
        "        self.min_child_weight = min_child_weight\n",
        "        self.lambda_ = lambda_\n",
        "        self.gamma = gamma\n",
        "        self.tree = {}\n",
        "        self.fbs_time = 0\n",
        "\n",
        "    def similarity(self, residual, probs):\n",
        "        nu = np.sum(residual) ** 2\n",
        "        de = np.sum(probs * (1 - probs)) + self.lambda_\n",
        "        return nu / de\n",
        "\n",
        "    def compute_output(self, residual, probs):\n",
        "        nu = np.sum(residual)\n",
        "        de = np.sum(probs * (1 - probs)) + self.lambda_\n",
        "        return nu / de\n",
        "\n",
        "    def cover(self, probs):\n",
        "        return np.sum(probs * (1 - probs))\n",
        "\n",
        "    def split_data(self, X, feature_idx, split_value):\n",
        "        left_idx = X[:, feature_idx] <= split_value\n",
        "        right_idx = X[:, feature_idx] > split_value\n",
        "        return left_idx, right_idx\n",
        "\n",
        "    def find_best_split(self, X, residual, probs):\n",
        "        best_gain = -np.inf\n",
        "        best_split_feature_idx = None\n",
        "        best_split_value = None\n",
        "\n",
        "        for feature_idx in range(X.shape[1]):\n",
        "            list_values = X[:, feature_idx]\n",
        "            list_unique = np.unique(list_values)\n",
        "\n",
        "            for i in range(len(list_unique) - 1):\n",
        "                value = (list_unique[i] + list_unique[i + 1]) / 2\n",
        "\n",
        "                left_idx, right_idx = self.split_data(X, feature_idx, value)\n",
        "                p_left = probs[left_idx]\n",
        "                p_right = probs[right_idx]\n",
        "\n",
        "                if (len(left_idx) < self.min_samples or len(right_idx) < self.min_samples\n",
        "                    or self.cover(p_left) < self.min_child_weight or self.cover(p_right) < self.min_child_weight):\n",
        "                    continue\n",
        "\n",
        "                r_left = residual[left_idx]\n",
        "                r_right = residual[right_idx]\n",
        "\n",
        "                gain = self.similarity(r_left, p_left) + self.similarity(r_right, p_right) - self.similarity(residual, probs)\n",
        "\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_split_feature_idx = feature_idx\n",
        "                    best_split_value = value\n",
        "\n",
        "        if(best_gain - self.gamma < 0):\n",
        "            best_split_feature_idx = None\n",
        "            best_split_value = None\n",
        "\n",
        "        return best_split_feature_idx, best_split_value\n",
        "\n",
        "    def build_tree(self, X, residual, probs, depth):\n",
        "        if depth >= self.max_depth or len(X) <= self.min_samples:\n",
        "            return self.compute_output(residual, probs)\n",
        "\n",
        "        start = time.time()\n",
        "        split_feature_idx, split_value = self.find_best_split(X, residual, probs)\n",
        "        end = time.time()\n",
        "        self.fbs_time += (end - start)\n",
        "\n",
        "        if split_feature_idx is None:\n",
        "            return self.compute_output(residual, probs)\n",
        "\n",
        "        left_idx, right_idx = self.split_data(X, split_feature_idx, split_value)\n",
        "        left = self.build_tree(X[left_idx], residual[left_idx], probs[left_idx], depth + 1)\n",
        "        right = self.build_tree(X[right_idx], residual[right_idx], probs[right_idx], depth + 1)\n",
        "\n",
        "        self.tree = {\n",
        "            'split_feature_idx': split_feature_idx,\n",
        "            'split_value': split_value,\n",
        "            'left_child': left,\n",
        "            'right_child': right\n",
        "        }\n",
        "        return self.tree\n",
        "\n",
        "    def get_output(self, x, tree):\n",
        "        if isinstance(tree, dict):\n",
        "            split_feature_idx = tree['split_feature_idx']\n",
        "            split_value = tree['split_value']\n",
        "            if x[split_feature_idx] <= split_value:\n",
        "                return self.get_output(x, tree['left_child'])\n",
        "            else:\n",
        "                return self.get_output(x, tree['right_child'])\n",
        "        else:\n",
        "            return tree\n",
        "\n",
        "    def fit(self, X, residual, probs):\n",
        "        depth = 0\n",
        "        self.tree = self.build_tree(X, residual, probs, depth)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self.get_output(x, self.tree) for x in X])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b30KzBDXJuy2"
      },
      "outputs": [],
      "source": [
        "class XGBoost:\n",
        "    def __init__(self, n_estimators, lr, lambda_ = 1e-7, gamma = 0, min_child_weight = 1, max_depth = 3):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.lr = lr\n",
        "        self.initial_pred = 0.5\n",
        "        self.lambda_ = lambda_\n",
        "        self.min_child_weight = min_child_weight\n",
        "        self.max_depth = max_depth\n",
        "        self.gamma = gamma\n",
        "        self.models = []\n",
        "        self.fbs_time = 0\n",
        "        self.logodds_time = 0\n",
        "        self.residual_time = 0\n",
        "        self.logodds_predict_time = 0\n",
        "        self.pred_time = 0\n",
        "\n",
        "    def compute_logodds(self, p):\n",
        "        return np.log(p / (1 - p))\n",
        "\n",
        "    def residual(self, y_true, y_pred):\n",
        "        return (y_true - y_pred)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        p = np.full(len(y), self.initial_pred)\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            probs = np.copy(p)\n",
        "            start = time.time()\n",
        "            residual = self.residual(y, p)\n",
        "            end = time.time()\n",
        "            self.residual_time += (end - start)\n",
        "\n",
        "            model = Tree(lambda_ = self.lambda_, gamma = self.gamma, max_depth = self.max_depth, min_child_weight = self.min_child_weight)\n",
        "            model.fit(X, residual, probs)\n",
        "            self.fbs_time += model.fbs_time\n",
        "\n",
        "            start = time.time()\n",
        "            log_odds = self.compute_logodds(p)\n",
        "            end = time.time()\n",
        "            self.logodds_time += (end - start)\n",
        "\n",
        "            start = time.time()\n",
        "            logodds_p = log_odds + self.lr * model.predict(X)\n",
        "            end = time.time()\n",
        "            self.logodds_predict_time += (end - start)\n",
        "\n",
        "            start = time.time()\n",
        "            p = np.exp(logodds_p) / (1 + np.exp(logodds_p))\n",
        "            end = time.time()\n",
        "            self.pred_time += (end - start)\n",
        "\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        pred = np.full(len(X), self.initial_pred)\n",
        "        for model in self.models:\n",
        "            logodds_p = self.compute_logodds(pred) + self.lr * model.predict(X)\n",
        "            pred = np.exp(logodds_p) / (1 + np.exp(logodds_p))\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1fZjrmlxvUH"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1x2IQyQTxvUI"
      },
      "outputs": [],
      "source": [
        "train = np.load('train_data.npz', allow_pickle = True)\n",
        "X_train = train['data']\n",
        "y_train = train['label']\n",
        "\n",
        "test = np.load('test_data.npz', allow_pickle = True)\n",
        "X_test = test['data']\n",
        "y_test = test['label']\n",
        "\n",
        "minimal_X_train = X_train[:3000]\n",
        "minimal_y_train = y_train[:3000]\n",
        "minimal_X_test = X_test[:600]\n",
        "minimal_y_test = y_test[:600]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWpVfHCBxvUI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEKKmFp7xvUI",
        "outputId": "1ee20117-41ec-468f-aa1f-1209dc5a8fba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9566666666666667"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xgb_model = XGBoost(3, 0.3)\n",
        "xgb_model.fit(minimal_X_train, (minimal_y_train == 0).astype(int))\n",
        "\n",
        "y_prob_pred = xgb_model.predict_proba(minimal_X_test)\n",
        "accuracy_score((minimal_y_test == 0).astype(int), (y_prob_pred > 0.5).astype(int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzoPeMsZxvUI"
      },
      "outputs": [],
      "source": [
        "''' Đọc data\n",
        "train = np.load('<tên file>.npz',allow_pickle=True)\n",
        "X_train = train['data']\n",
        "y_train = train['label']\n",
        "\n",
        "test = np.load('<tên file>.npz',allow_pickle=True)\n",
        "X_test = test['data']\n",
        "y_test = test['label']\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubdkjix7xvUJ"
      },
      "outputs": [],
      "source": [
        "''' Mã giả của MultiClassifier\n",
        "class Multi:\n",
        "    __init__():\n",
        "        self.models = []\n",
        "        self.time = 0\n",
        "\n",
        "    fit():\n",
        "        for y_i in labels:\n",
        "            y_2labels = (y == y_i).astype(int)\n",
        "            model = XGBoost(...)\n",
        "            model.fit(X, y_2labels)\n",
        "            self.models.append(model)\n",
        "            Tính thời gian + lưu thời gian\n",
        "\n",
        "    predict():\n",
        "        preds = []\n",
        "        for model in self.models:\n",
        "            preds.append(model.predict_proba(X_test))\n",
        "        y_pred = np.argmax(preds, axis = 0)\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    show_time():  -> để show ra hàm nào mất thời gian nhất & cần song song -> tùy ý\n",
        "        ....\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "p2JWAVdPWW5m"
      },
      "outputs": [],
      "source": [
        "class MultiClassifier:\n",
        "  def __init__(self):\n",
        "    self.models = []\n",
        "    self.training_time = 0\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    start_time = time.time()\n",
        "    for label in np.unique(y):\n",
        "      binary_labels = (y == label).astype(int)\n",
        "      model = XGBoost(3, 0.3)\n",
        "      model.fit(X, binary_labels)\n",
        "      self.models.append(model)\n",
        "    end_time = time.time()\n",
        "    self.training_time += (end_time - start_time)\n",
        "\n",
        "  def predict(self, X):\n",
        "    preds = []\n",
        "    for model in self.models:\n",
        "      preds.append(model.predict_proba(X))\n",
        "\n",
        "    return np.argmax(preds, axis = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IzY9Bxcqk8UQ"
      },
      "outputs": [],
      "source": [
        "train_3labels = np.load('train_data_3labels.npz', allow_pickle = True)\n",
        "X_train_3labels = train_3labels['data']\n",
        "y_train_3labels = train_3labels['label']\n",
        "\n",
        "test_3labels = np.load('test_data_3labels.npz', allow_pickle = True)\n",
        "X_test_3labels = test_3labels['data']\n",
        "y_test_3labels = test_3labels['label']\n",
        "\n",
        "minimal_X_train = X_train[:3000]\n",
        "minimal_y_train = y_train[:3000]\n",
        "minimal_X_test = X_test[:600]\n",
        "minimal_y_test = y_test[:600]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOuEpRYFpSWX",
        "outputId": "edba3738-ed74-4513-d6f5-c028513eebb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9566666666666667"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_classifier = MultiClassifier()\n",
        "multi_classifier.fit(X_train_3labels, y_train_3labels)\n",
        "\n",
        "y_pred = multi_classifier.predict(X_test_3labels)\n",
        "accuracy_score(y_test_3labels, y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
