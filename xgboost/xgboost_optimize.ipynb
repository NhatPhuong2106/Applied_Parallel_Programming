{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5-KyM3YaUOs"
      },
      "source": [
        "## Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Uf7CxvnGUzot"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "from numba import cuda\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N9O6QF9aUO2"
      },
      "source": [
        "## Cài đặt phiên bản XGBoost cải tiến"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-8MdE_AaUO3"
      },
      "source": [
        "Áp dụng một số cải tiến giúp cải thiện hiệu suất mô hình, giảm số lần truy cập bộ nhớ, giảm thời gian thực thi nhưng vẫn đảm bảo được độ chính xác của mô hình"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFEeUf09aUO4"
      },
      "source": [
        "#### Xét hàm **`compute_split_value()`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNojeG-ez5-b"
      },
      "source": [
        "Tạo hàm `compute_split_value_optimize()` áp dụng các kĩ thuật cải tiến lên hàm song song hóa ban đầu\n",
        "\n",
        "- Cải tiến 1: Trong quá trình transfer dữ liệu từ CPU/Host sang GPU/Device, Numba mặc định sẽ tự động copy dữ liệu của các tham số truyền vào hàm kernel từ Host sang Device, sau khi chạy xong hàm kernel thì sẽ copy các tham số truyền vào trước đó ngược lại về Host. Để tối ưu, ta chỉ cần copy dữ liệu cần thiết và bỏ qua dữ liệu không cần thiết khi transfer dữ liệu từ Host sang Device và Device về lại Host.\n",
        "  \n",
        "- Cải tiến 2: Dữ liệu của sample X nằm ở bộ nhớ GMEM, và mỗi lần đọc dữ liệu của X thì các thread đều phải chạy xuống GMEM. Vì vậy sử dụng SMEM chứa phần dữ liệu mong muốn để tính split_value. Giả sử kích thước block là 4 x 4, thì kích thước share là 5 x 4 (vì 1 $split\\_value$ element cần 2 $x$ elements). Các thread sẽ lấy phần dữ liệu ứng với chỉ số `(row, col)` của chúng và ghi vào SMEM, đối với phần dữ liệu còn lại sẽ do thread liền trước đó xử lý"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BOJEnHqaU1Bf"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def compute_split_value_optimize(input, output):\n",
        "    shared = cuda.shared.array((33, 32), dtype = np.float64)\n",
        "    r = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
        "    c = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "    tx, ty = cuda.threadIdx.x, cuda.threadIdx.y\n",
        "\n",
        "    if r < output.shape[0] and c < output.shape[1]:\n",
        "        shared[ty, tx] = input[r, c]\n",
        "\n",
        "        if ty == cuda.blockDim.y - 1 or r == output.shape[0] - 1:\n",
        "            shared[ty + 1, tx] = input[r + 1, c]\n",
        "\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        if shared[ty, tx] != shared[ty + 1, tx]:\n",
        "            tmp = (shared[ty, tx] + shared[ty + 1, tx]) / 2\n",
        "            output[r, c] = tmp\n",
        "        else:\n",
        "            output[r, c] = np.nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLsVTr45aUO7"
      },
      "source": [
        "#### Xét hàm **`compute_gain()`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n1z6NWrVY7R"
      },
      "source": [
        "Tạo hàm `compute_gain_optimize()` áp dụng các kĩ thuật cải tiến lên hàm song song hóa ban đầu\n",
        "\n",
        "- Cải tiến 1: Tương tự với cải tiến 1 của hàm `compute_split_value_optimize()`, ta chỉ cần copy dữ liệu cần thiết khi transfer dữ liệu từ Host sang Device và chỉ lấy ra kết quả là dãy giá trị gain tính được từ Device về Host memory\n",
        "  \n",
        "- Cải tiến 2: Dữ liệu của X, residual, prob và root gain đều nằm ở bộ nhớ GMEM, mỗi lần đọc dữ liệu thì các thread đều phải chạy xuống GMEM. Do vậy sử dụng SMEM load phần dữ liệu X, residual, prob, root gain mong muốn, phục vụ cho việc so sánh giá trị và tính gain. Với root gain, ta sẽ để thread có chỉ số `(tx = 0, ty = 0)` load dữ liệu vào SMEM. Với các dữ liệu còn lại, ta sẽ chia phần dữ liệu mà block cần thành nhiều phần nhỏ. Ở lần xử lý đầu tiên, block sẽ load một phần nhỏ của dữ liệu từ GMEM vào SMEM, rồi mỗi thread trong block đọc dữ liệu ở SMEM để tính một phần kết quả; ở lần xử lý kế, block sẽ load phần nhỏ tiếp theo (ghi đè lên dữ liệu cũ) và tính tiếp từ kết quả đang tính trước đó, tiếp tục cho đến hết."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ew5kLAPoP0Ma"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def compute_gain_optimize(split, output, X, residuals, p, lambda_, min_child_weight, min_samples, root_gain):\n",
        "    c, r = cuda.grid(2)\n",
        "    tx, ty = cuda.threadIdx.x, cuda.threadIdx.y\n",
        "    shared_X = cuda.shared.array((32, 32), dtype = np.float64)\n",
        "    shared_residual = cuda.shared.array((32), dtype = np.float64)\n",
        "    shared_prob = cuda.shared.array((32), dtype = np.float64)\n",
        "    shared_root_gain = cuda.shared.array((1), dtype = np.float64)\n",
        "    left_nu, right_nu, left_de, right_de, left_samples, right_samples = 0, 0, 0, 0, 0, 0\n",
        "\n",
        "    if r < split.shape[0] and c < split.shape[1]:\n",
        "        split_val = split[r, c]\n",
        "    else:\n",
        "        split_val = np.nan\n",
        "    if tx == 0 and ty == 0:\n",
        "        shared_root_gain[0] = root_gain\n",
        "\n",
        "    for phase in range(math.ceil(X.shape[0] / 32)):\n",
        "        if c < X.shape[1] and phase * 32 + ty < X.shape[0]:\n",
        "            shared_X[ty, tx] = X[phase * 32 + ty, c]\n",
        "            if tx == 0:\n",
        "                shared_residual[ty] = residuals[phase * 32 + ty]\n",
        "                shared_prob[ty] = p[phase * 32 + ty]\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        if split_val != np.nan:\n",
        "            for i in range(shared_X.shape[0]):\n",
        "                if phase * 32 + i < X.shape[0]:\n",
        "                    if shared_X[i, tx] <= split_val:\n",
        "                        left_nu += shared_residual[i]\n",
        "                        left_de += shared_prob[i] * (1 - shared_prob[i])\n",
        "                        left_samples += 1\n",
        "                    else:\n",
        "                        right_nu += shared_residual[i]\n",
        "                        right_de += shared_prob[i] * (1 - shared_prob[i])\n",
        "                        right_samples += 1\n",
        "            cuda.syncthreads()\n",
        "\n",
        "    if r < split.shape[0] and c < split.shape[1]:\n",
        "        if (left_samples < min_samples or right_samples < min_samples\n",
        "            or left_de < min_child_weight or right_de < min_child_weight ):\n",
        "            output[r, c] = np.nan\n",
        "        else:\n",
        "            left_sim = (left_nu ** 2) / (left_de + lambda_)\n",
        "            right_sim = (right_nu ** 2) / (right_de + lambda_)\n",
        "            gain = left_sim + right_sim - shared_root_gain[0]\n",
        "            output[r, c] = gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "34CoLI_eUzo2"
      },
      "outputs": [],
      "source": [
        "class Tree:\n",
        "    def __init__(self, max_depth = 3, min_samples = 1, min_child_weight = 1, lambda_ = 0, gamma = 0):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples = min_samples\n",
        "        self.min_child_weight = min_child_weight\n",
        "        self.lambda_ = lambda_\n",
        "        self.gamma = gamma\n",
        "        self.tree = {}\n",
        "        self.fbs_time = 0\n",
        "\n",
        "    def similarity(self, residual, probs):\n",
        "        nu = np.sum(residual) ** 2\n",
        "        de = np.sum(probs * (1 - probs)) + self.lambda_\n",
        "        return nu / de\n",
        "\n",
        "    def compute_output(self, residual, probs):\n",
        "        nu = np.sum(residual)\n",
        "        de = np.sum(probs * (1 - probs)) + self.lambda_\n",
        "        return nu / de\n",
        "\n",
        "    def split_data(self, X, feature_idx, split_value):\n",
        "        left_idx = X[:, feature_idx] <= split_value\n",
        "        right_idx = X[:, feature_idx] > split_value\n",
        "        return left_idx, right_idx\n",
        "\n",
        "    def find_best_split(self, X, residuals, probs):\n",
        "        best_gain = -np.inf\n",
        "        best_split_feature_idx = None\n",
        "        best_split_value = None\n",
        "\n",
        "        split_array = np.empty((X.shape[0] - 1, X.shape[1]))\n",
        "        #allocate and transfer data from Host to Device memory\n",
        "        d_split_array = cuda.device_array(split_array.shape)\n",
        "        # d_X = cuda.to_device(np.sort(X, axis = 0).astype(np.float64))\n",
        "        d_X = cuda.to_device(X)\n",
        "\n",
        "        block_size = (32, 32)\n",
        "        grid_split = (math.ceil(split_array.shape[1] / block_size[0]),\n",
        "                      math.ceil(split_array.shape[0] / block_size[1]))\n",
        "        # compute_split_value_optimize[grid_split, block_size](np.sort(X, axis=0).astype(np.float64), split_array)\n",
        "        compute_split_value_optimize[grid_split, block_size](np.sort(d_X, axis=0).astype(np.float64), d_split_array)\n",
        "        #transfer result back to Host\n",
        "        split_array = d_split_array.copy_to_host()\n",
        "\n",
        "        root_gain = self.similarity(residuals, probs)\n",
        "        gain_array = np.empty((split_array.shape[0], split_array.shape[1]))\n",
        "        #allocate and transfer data from host to device memory\n",
        "        d_split_array = cuda.to_device(split_array)\n",
        "        d_gain_array = cuda.device_array(gain_array.shape)\n",
        "        d_residuals = cuda.to_device(residuals)\n",
        "        d_probs = cuda.to_device(probs)\n",
        "        grid_gain = (math.ceil(gain_array.shape[1] / block_size[0]),\n",
        "                     math.ceil(gain_array.shape[0] / block_size[1]))\n",
        "\n",
        "        # compute_gain_optimize[grid_gain, block_size](split_array, gain_array, X, residuals,\n",
        "        #                                     probs, self.lambda_, self.min_child_weight, self.min_samples, root_gain)\n",
        "\n",
        "        compute_gain_optimize[grid_gain, block_size](d_split_array, d_gain_array, d_X, d_residuals,\n",
        "                                            d_probs, self.lambda_, self.min_child_weight, self.min_samples, root_gain)\n",
        "        #transfer result back to Host\n",
        "        gain_array = d_gain_array.copy_to_host()\n",
        "\n",
        "        gain_array[np.isnan(gain_array)] = -np.inf\n",
        "        if np.sum(gain_array == -np.inf) != (gain_array.shape[0] * gain_array.shape[1]):\n",
        "            tmp_gain = np.transpose(gain_array)\n",
        "            max_idx = np.unravel_index(tmp_gain.argmax(), tmp_gain.shape)\n",
        "            final_idx = (max_idx[1], max_idx[0])\n",
        "            best_split_feature_idx = final_idx[1]\n",
        "            best_gain = gain_array[final_idx]\n",
        "            best_split_value = split_array[final_idx]\n",
        "\n",
        "        if(best_gain - self.gamma < 0):\n",
        "            best_split_feature_idx = None\n",
        "            best_split_value = None\n",
        "\n",
        "        return best_split_feature_idx, best_split_value\n",
        "\n",
        "    def build_tree(self, X, residual, probs, depth):\n",
        "        if depth >= self.max_depth or len(X) <= self.min_samples:\n",
        "            return self.compute_output(residual, probs)\n",
        "\n",
        "        start = time.time()\n",
        "        split_feature_idx, split_value = self.find_best_split(X, residual, probs)\n",
        "        end = time.time()\n",
        "        self.fbs_time += (end - start)\n",
        "\n",
        "        if split_feature_idx is None:\n",
        "            return self.compute_output(residual, probs)\n",
        "\n",
        "        left_idx, right_idx = self.split_data(X, split_feature_idx, split_value)\n",
        "        left = self.build_tree(X[left_idx], residual[left_idx], probs[left_idx], depth + 1)\n",
        "        right = self.build_tree(X[right_idx], residual[right_idx], probs[right_idx], depth + 1)\n",
        "\n",
        "        self.tree = {\n",
        "            'split_feature_idx': split_feature_idx,\n",
        "            'split_value': split_value,\n",
        "            'left_child': left,\n",
        "            'right_child': right\n",
        "        }\n",
        "        return self.tree\n",
        "\n",
        "    def get_output(self, x, tree):\n",
        "        if isinstance(tree, dict):\n",
        "            split_feature_idx = tree['split_feature_idx']\n",
        "            split_value = tree['split_value']\n",
        "            if x[split_feature_idx] <= split_value:\n",
        "                return self.get_output(x, tree['left_child'])\n",
        "            else:\n",
        "                return self.get_output(x, tree['right_child'])\n",
        "        else:\n",
        "            return tree\n",
        "\n",
        "    def fit(self, X, residual, probs):\n",
        "        depth = 0\n",
        "        self.tree = self.build_tree(X, residual, probs, depth)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self.get_output(x, self.tree) for x in X])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Xét các hàm **`residual_optimize()`**, **`compute_logodds_optimize()`**, **`compute_prob_optimize()`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzes5uuzVr8K"
      },
      "source": [
        "Các hàm `residual_optimize()` , `compute_logodds_optimize()`, `compute_prob_optimize()` sẽ cho mỗi thread block xử lý $2 * blockDim.x$ phần tử. Tất cả các thread trong mỗi block sẽ xử lý $blockDim.x$ phần tử đầu mảng, mỗi thread xử lý một phần tử, sau đó tất cả các thread sẽ chuyển sang $blockDim.x$ phần tử sau của mảng, mỗi thread xử lý một phần tử. Tương tự với các hàm tối ưu trước, chỉ copy dữ liệu cần thiết khi transfer dữ liệu từ Host sang Device và copy mảng kết quả về Host memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sJayi1-KUzo5"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def residual_kernel(y_true, y_pred, residual):\n",
        "    i = cuda.blockIdx.x * cuda.blockDim.x * 2 + cuda.threadIdx.x\n",
        "    if i < residual.shape[0]:\n",
        "        residual[i] = y_true[i] - y_pred[i]\n",
        "    if i + cuda.blockDim.x < residual.shape[0]:\n",
        "        residual[i + cuda.blockDim.x] = y_true[i + cuda.blockDim.x] - y_pred[i + cuda.blockDim.x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PtykeywPUzo7"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def compute_logodds_kernel(p, log_odds):\n",
        "    i = cuda.blockIdx.x * cuda.blockDim.x * 2 + cuda.threadIdx.x\n",
        "    if i < log_odds.shape[0]:\n",
        "        log_odds[i] = math.log(p[i] / (1 - p[i]))\n",
        "    if i + cuda.blockDim.x < log_odds.shape[0]:\n",
        "        log_odds[i + cuda.blockDim.x] = math.log(p[i + cuda.blockDim.x] / (1 - p[i + cuda.blockDim.x]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Rn1IpYyBUzo8"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def compute_prob_kernel(logodds_p, p):\n",
        "    i = cuda.blockIdx.x * cuda.blockDim.x * 2 + cuda.threadIdx.x\n",
        "    if i < p.shape[0]:\n",
        "        p[i] = math.exp(logodds_p[i]) / (1 + math.exp(logodds_p[i]))\n",
        "    if i + cuda.blockDim.x < p.shape[0]:\n",
        "        p[i + cuda.blockDim.x] = math.exp(logodds_p[i + cuda.blockDim.x]) / (1 + math.exp(logodds_p[i + cuda.blockDim.x]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "E8SxzYNhUzo8"
      },
      "outputs": [],
      "source": [
        "class XGBoost:\n",
        "    def __init__(self, n_estimators, lr, lambda_ = 0, gamma = 0, min_child_weight = 1, max_depth = 3):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.lr = lr\n",
        "        self.initial_pred = 0.5\n",
        "        self.lambda_ = lambda_\n",
        "        self.min_child_weight = min_child_weight\n",
        "        self.max_depth = max_depth\n",
        "        self.gamma = gamma\n",
        "        self.models = []\n",
        "        self.fbs_time = 0\n",
        "        self.logodds_time = 0\n",
        "        self.residual_time = 0\n",
        "        self.predict_time = 0\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        p = np.full(len(y), self.initial_pred)\n",
        "        block_size = 32\n",
        "        grid_size = math.ceil(len(y) / 2 * block_size)\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            probs = np.copy(p)\n",
        "\n",
        "            residual = np.empty(len(y))\n",
        "            d_y = cuda.to_device(y)\n",
        "            d_p = cuda.to_device(p)\n",
        "            d_residual = cuda.device_array(residual.shape)\n",
        "            start = time.time()\n",
        "            # residual_kernel[grid_size, block_size](y, p, residual)\n",
        "            residual_kernel[grid_size, block_size](d_y, d_p, d_residual)\n",
        "            residual = d_residual.copy_to_host()\n",
        "\n",
        "            end = time.time()\n",
        "            self.residual_time += (end - start)\n",
        "\n",
        "            model = Tree(lambda_ = self.lambda_, gamma = self.gamma, max_depth = self.max_depth, min_child_weight = self.min_child_weight)\n",
        "            model.fit(X, residual, probs)\n",
        "            self.fbs_time += model.fbs_time\n",
        "\n",
        "            log_odds = np.empty(len(y))\n",
        "            d_log_odds = cuda.device_array(log_odds.shape)\n",
        "            start = time.time()\n",
        "            # compute_logodds_kernel[grid_size, block_size](p, log_odds)\n",
        "            compute_logodds_kernel[grid_size, block_size](d_p, d_log_odds)\n",
        "            log_odds = d_log_odds.copy_to_host()\n",
        "            end = time.time()\n",
        "            self.logodds_time += (end - start)\n",
        "\n",
        "            p = np.empty(len(y))\n",
        "            d_p = cuda.device_array(p.shape)\n",
        "            start = time.time()\n",
        "            logodds_p = log_odds + self.lr * model.predict(X)\n",
        "            d_logodds_p = cuda.to_device(logodds_p)\n",
        "            # compute_prob_kernel[grid_size, block_size](logodds_p, p)\n",
        "            compute_prob_kernel[grid_size, block_size](d_logodds_p, d_p)\n",
        "            p = d_p.copy_to_host()\n",
        "            end = time.time()\n",
        "            self.predict_time += (end - start)\n",
        "\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        pred = np.full(len(X), self.initial_pred)\n",
        "        block_size = 32\n",
        "        grid_size = math.ceil(len(X) / 2 * block_size)\n",
        "        for model in self.models:\n",
        "            log_odds = np.empty(len(X))\n",
        "            d_log_odds = cuda.device_array(log_odds.shape)\n",
        "            d_pred = cuda.to_device(pred)\n",
        "            # compute_logodds_kernel[grid_size, block_size](pred, log_odds)\n",
        "            compute_logodds_kernel[grid_size, block_size](d_pred, d_log_odds)\n",
        "            log_odds = d_log_odds.copy_to_host()\n",
        "            logodds_p = log_odds + self.lr * model.predict(X)\n",
        "            pred = np.empty(len(X))\n",
        "            d_logodds_p = cuda.to_device(logodds_p)\n",
        "            d_pred = cuda.device_array(pred.shape)\n",
        "            # compute_prob_kernel[grid_size, block_size](logodds_p, pred)\n",
        "            compute_prob_kernel[grid_size, block_size](d_logodds_p, d_pred)\n",
        "            pred = d_pred.copy_to_host()\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Xây dựng mô hình đa lớp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mgEyri5UUzo9"
      },
      "outputs": [],
      "source": [
        "class MultiClassifier:\n",
        "    def __init__(self, n_estimators = 3, lr = 0.3):\n",
        "        self.models = []\n",
        "        self.n_estimators = n_estimators\n",
        "        self.lr = lr\n",
        "        self.training_time = 0\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        start_time = time.time()\n",
        "        for label in np.unique(y):\n",
        "            binary_labels = (y == label).astype(int)\n",
        "            model = XGBoost(self.n_estimators, self.lr)\n",
        "            model.fit(X, binary_labels)\n",
        "            self.models.append(model)\n",
        "        end_time = time.time()\n",
        "        self.training_time += (end_time - start_time)\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = []\n",
        "        for model in self.models:\n",
        "            preds.append(model.predict_proba(X))\n",
        "        return np.argmax(preds, axis = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chạy mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0W8GRXIAUzo_"
      },
      "outputs": [],
      "source": [
        "train = np.load('train_data_3labels.npz', allow_pickle = True)\n",
        "X_train = train['data']\n",
        "y_train = train['label']\n",
        "\n",
        "test = np.load('test_data_3labels.npz', allow_pickle = True)\n",
        "X_test = test['data']\n",
        "y_test = test['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Binary classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JxlMmvMYUzpA",
        "outputId": "8b2f2c4f-3c0e-441c-c455-dc43a994dc99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9466666666666667\n",
            "Total time: 2.5445396900177 seconds\n"
          ]
        }
      ],
      "source": [
        "binary_classifier = XGBoost(n_estimators = 3, lr = 0.3)\n",
        "start_time = time.time()\n",
        "binary_classifier.fit(X_train, (y_train == 0).astype(int))\n",
        "end_time = time.time()\n",
        "\n",
        "y_prob_pred = binary_classifier.predict_proba(X_test)\n",
        "binary_labels_pred = (y_prob_pred > 0.5).astype(int)\n",
        "binary_labels_test = (y_test == 0).astype(int)\n",
        "\n",
        "accuracy_binary = accuracy_score(binary_labels_test, binary_labels_pred)\n",
        "time_binary = end_time - start_time\n",
        "\n",
        "print('Accuracy:', accuracy_binary)\n",
        "print(f'Total time: {time_binary} seconds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Multi classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XoyRN4JPUzpA",
        "outputId": "437fed48-c9e1-4d5d-e1f1-354211420586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9566666666666667\n",
            "Total time: 7.652122974395752 seconds\n"
          ]
        }
      ],
      "source": [
        "multi_classifier = MultiClassifier()\n",
        "multi_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = multi_classifier.predict(X_test)\n",
        "accuracy_3labels = accuracy_score(y_test, y_pred)\n",
        "time_3labels = multi_classifier.training_time\n",
        "\n",
        "print('Accuracy:', accuracy_3labels)\n",
        "print(f'Total time: {time_3labels} seconds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Multi classification trên tập dữ liệu hoàn chỉnh (10 lớp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8j2oONMSUzpB"
      },
      "outputs": [],
      "source": [
        "train = np.load('train_data.npz', allow_pickle = True)\n",
        "X_train = train['data']\n",
        "y_train = train['label']\n",
        "\n",
        "test = np.load('test_data.npz', allow_pickle = True)\n",
        "X_test = test['data']\n",
        "y_test = test['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yJPIHXGiUzpC",
        "outputId": "7e825a41-6334-4df2-c280-5deaaf388cb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.891\n",
            "Total time: 2589.382884502411 seconds\n"
          ]
        }
      ],
      "source": [
        "multi_classifier = MultiClassifier(n_estimators = 35, lr = 0.3)\n",
        "multi_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = multi_classifier.predict(X_test)\n",
        "accuracy_10labels = accuracy_score(y_test, y_pred)\n",
        "time_10label = multi_classifier.training_time\n",
        "\n",
        "print('Accuracy:', accuracy_10labels)\n",
        "print(f'Total time: {time_10label} seconds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Kết luận:** Phiên bản optimize đã cải thiện tốt thời gian huấn luyện nhưng vẫn đảm bảo được độ chính xác trong mọi trường hợp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUwE7c_Nb2qJ"
      },
      "source": [
        "## Lưu kết quả"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZzAz_46ka4hj"
      },
      "outputs": [],
      "source": [
        "result_df = pd.read_csv('result.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TAzFfhZwa5eM"
      },
      "outputs": [],
      "source": [
        "result_df['Optimize_training_time'] = [time_binary, time_3labels, time_10label]\n",
        "result_df['Optimize_accuracy'] = [accuracy_binary, accuracy_3labels, accuracy_10labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_yQ-flFtbz3h"
      },
      "outputs": [],
      "source": [
        "result_df.to_csv('result.csv', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8a-isreawnQ"
      },
      "source": [
        "## Under sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "A5MsxlZCUzpC"
      },
      "outputs": [],
      "source": [
        "class MultiClassifier_2:\n",
        "    def __init__(self, n_estimators = 3, lr = 0.3):\n",
        "        self.models = []\n",
        "        self.n_estimators = n_estimators\n",
        "        self.lr = lr\n",
        "        self.training_time = 0.0\n",
        "\n",
        "    def under_sampling(self, X, y):\n",
        "        size = int((np.count_nonzero(y)) * 1.5)\n",
        "        random_idx = np.random.choice(len(np.where(y == 0)[0]), size = size)\n",
        "        idx = np.concatenate([np.where(y == 1)[0], random_idx])\n",
        "        return X[idx], y[idx]\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        start_time = time.time()\n",
        "        for label in np.unique(y):\n",
        "            binary_labels = (y == label).astype(int)\n",
        "            X_balance, y_balance = self.under_sampling(X, binary_labels)\n",
        "            model = XGBoost(self.n_estimators, self.lr)\n",
        "            model.fit(X_balance, y_balance)\n",
        "            self.models.append(model)\n",
        "        end_time = time.time()\n",
        "        self.training_time += (end_time - start_time)\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = []\n",
        "        for model in self.models:\n",
        "            preds.append(model.predict_proba(X))\n",
        "        return np.argmax(preds, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4xllwC3IQBtD",
        "outputId": "a0d4f6af-d25e-4f2f-a8f7-167f606dc2ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.924\n",
            "Precision: [0.95145631 0.87272727 0.82142857 0.95744681 0.96551724 0.87037037\n",
            " 0.91666667 0.94949495 0.98989899 0.97826087]\n",
            "Total time: 601.2597625255585 seconds\n"
          ]
        }
      ],
      "source": [
        "multi_classifier = MultiClassifier_2(n_estimators = 100, lr = 0.3)\n",
        "multi_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = multi_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average = None)\n",
        "training_time = multi_classifier.training_time\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('Precision:', precision)\n",
        "print(f'Total time: {training_time} seconds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sử dụng under sampling trên phiên bản optimize giúp cho mô hình chạy với thời gian nhanh hơn, accuracy và precision cho thấy kết quả dự đoán của mô hình khá tốt."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
